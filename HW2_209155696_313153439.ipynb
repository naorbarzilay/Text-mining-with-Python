{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620f7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.metrics.distance  import edit_distance\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfb0bc",
   "metadata": {},
   "source": [
    "<h1 style='color:red'>Q1 - Regular Expressions:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff00c74",
   "metadata": {},
   "source": [
    "<h4 style='color:black'><u>Functions:</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3db09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Time(string):\n",
    "    return [w for w in string if re.search(r'^([0-1][0-9]|2[0-3]):[0-5][0-9]$', w)]\n",
    "\n",
    "def get_Phonenumber(string):\n",
    "    list_numbers=[]\n",
    "    list_numbers.append(re.findall(r'0[2,3,4,8,9]-?\\d{3}-?\\d{4}', string))\n",
    "    list_numbers.append(re.findall(r'\\(05[0,2,3,4,5,8]\\) \\d{7}', string))\n",
    "    list_numbers.append(re.findall(r'(05[0,2,3,4,5,8]-?\\d{7})\\b', string))\n",
    "    return list_numbers\n",
    "\n",
    "def get_Comments(string):\n",
    "    return re.findall(r'/\\*.*?\\*/', string)\n",
    "    \n",
    "def get_thirty_num(string):  \n",
    "    return re.findall(r'thirty(?:-one|-two|-three|-four|-five|-six|-seven|-eight|-nine)?\\b', string)\n",
    "\n",
    "def get_Dates(string): \n",
    "    return [w for w in string.split() if re.search(r'^\\d{4}[\\-\\/\\s]?((((0[13578])|(1[02]))[\\-\\/\\s]?(([0-2][0-9])|(3[01])))|(((0[469])|(11))[\\-\\/\\s]?(([0-2][0-9])|(30)))|(02[\\-\\/\\s]?[0-2][0-9]))$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0186b7",
   "metadata": {},
   "source": [
    "<h1 style='color:red'>Q2 - Similarity between strings:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195eb718",
   "metadata": {},
   "source": [
    "<h4 style='color:black'><u>Helper Functions</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed223b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_error_string(string): # find the error in the string \n",
    "    return re.findall(r'<ERR\\starg=.*?</ERR>', string)\n",
    "\n",
    "def get_tuples(list_errors): #make tuples of (current word, error word)\n",
    "    list_tuples = []\n",
    "    for error in list_errors:\n",
    "        cur_word = error[error.find('=')+1:error.find('>')]\n",
    "        mis_word = error[error.find('>')+2:error.find('/')-2]\n",
    "        list_tuples.append((cur_word,mis_word))\n",
    "        \n",
    "    return(list_tuples)\n",
    "\n",
    "def get_distance(list_tuples): # get a list of tuples and add to the tuples the distance -> (cur word, error word , distance)\n",
    "    tuples_with_dis=[]\n",
    "    for words_tuple in list_tuples:\n",
    "        distance=nltk.edit_distance(words_tuple[0],words_tuple[1]) # compute distance \n",
    "        tuples_with_dis.append((words_tuple[0],words_tuple[1],distance))\n",
    "    return tuples_with_dis\n",
    "            \n",
    "def get_number_of_distance(list_tuples,distance, operator): # 1- equal , 2- >distance (bigger than)\n",
    "    count=0\n",
    "    for words_tuple in list_tuples:\n",
    "        if(operator ==1):\n",
    "            if(words_tuple[2] == distance):\n",
    "                count+=1\n",
    "        if(operator ==2):\n",
    "            if(words_tuple[2] > distance):\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "def get_list_by_distance(list_tuples,distance,operator): # 1- equal , 2- >distance (bigger than)\n",
    "    list_by_distance=[]\n",
    "    for words_tuple in list_tuples:\n",
    "        if(operator ==1):\n",
    "            if(words_tuple[2] == distance):\n",
    "                list_by_distance.append((words_tuple[0].lower(),words_tuple[1].lower()))\n",
    "        if(operator ==2):\n",
    "            if(words_tuple[2] > distance):\n",
    "                list_by_distance.append((words_tuple[0].lower(),words_tuple[1].lower()))\n",
    "    return list_by_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e8a38",
   "metadata": {},
   "source": [
    "<h4 style='color:black'><u>Pre-Processing </u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e786020",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('misspellings_and_corrections.txt') as f: #open the file into lines\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines_string = ' '.join(str(line) for line in lines)\n",
    "error_lines = get_error_string(lines_string)\n",
    "cor_mis_tuples_list = get_tuples(error_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f37d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_string = ' '.join(str(line) for line in lines)\n",
    "error_lines = get_error_string(lines_string)\n",
    "cor_mis_tuples_list = get_tuples(error_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ae460",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>A:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b00d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sister', 'siter', 1),\n",
       " ('sister', 'siter', 1),\n",
       " ('goes', 'go', 2),\n",
       " ('sometimes', 'some times', 1),\n",
       " ('sometimes', 'some times', 1),\n",
       " ('club', 'clob', 1),\n",
       " ('bellringing', 'bell ringing', 1),\n",
       " ('watch', 'wakh', 2),\n",
       " ('front', 'frount', 1),\n",
       " ('second', 'sexeon', 3),\n",
       " ('watch', 'wach', 1),\n",
       " ('watch', 'wach', 1),\n",
       " ('cowboys', 'cow Boys', 2),\n",
       " ('sometimes', 'some times', 1),\n",
       " ('club', 'colbe', 3),\n",
       " ('watch', 'wach', 1),\n",
       " ('watch', 'wach', 1),\n",
       " ('think', 'thing', 1),\n",
       " ('TV', 'tv', 2),\n",
       " ('square', 'squar', 1),\n",
       " ('eyes', 'iyes', 1),\n",
       " (\"o'clock\", 'oclock', 1),\n",
       " ('knocked', 'nock', 3),\n",
       " ('at', 'a', 1),\n",
       " (\"o'clock\", 'oclock', 1),\n",
       " ('killed', 'kild', 2),\n",
       " ('saw', 'see', 2),\n",
       " ('been', 'bean', 1),\n",
       " ('knocked', 'nock', 3),\n",
       " ('called', 'cald', 2),\n",
       " ('came', 'cam', 1),\n",
       " ('killed', 'killd', 1),\n",
       " ('there', 'the', 2),\n",
       " ('Her', 'Here', 1),\n",
       " ('eyes', 'iyes', 1),\n",
       " ('have to', 'haveto', 1),\n",
       " ('before', 'be for', 2),\n",
       " ('anything', 'any thing', 1),\n",
       " ('else', 'als', 2),\n",
       " ('wheel', 'weel', 1),\n",
       " ('wheel', 'weel', 1),\n",
       " ('sallies', 'sally', 3),\n",
       " ('others', 'other', 1),\n",
       " ('rounds', 'rouns', 1),\n",
       " ('do', 'don', 1),\n",
       " ('ring', 'rings', 1),\n",
       " ('be', 'we', 1),\n",
       " ('breaks', 'brakes', 2),\n",
       " ('careful', 'carfull', 2),\n",
       " (\"Cynthia's\", 'Cynthia', 2),\n",
       " ('gas', 'gass', 1),\n",
       " ('masks', 'marsks', 1),\n",
       " ('floor', 'foor', 1),\n",
       " ('what', 'wat', 1),\n",
       " ('gas', 'gass', 1),\n",
       " ('masks', 'marsks', 1),\n",
       " ('too', 'to', 1),\n",
       " ('what', 'wat', 1),\n",
       " ('wash', 'wosh', 1),\n",
       " ('perhaps', 'prasp', 4),\n",
       " ('ate', 'et', 2),\n",
       " ('before', 'be for', 2),\n",
       " ('his', 'is', 1),\n",
       " ('pony', 'poney', 1),\n",
       " ('whiskey', 'wiskey', 1),\n",
       " ('soap', 'soape', 1),\n",
       " ('whiskey', 'wiskey', 1),\n",
       " ('gave', 'cave', 1),\n",
       " ('gave', 'cave', 1),\n",
       " ('got', 'go', 1),\n",
       " ('her', 'here', 1),\n",
       " ('her', 'here', 1),\n",
       " ('soap', 'sope', 2),\n",
       " ('what', 'wat', 1),\n",
       " ('her', 'here', 1),\n",
       " ('gave', 'cave', 1),\n",
       " ('whiskey', 'wiskey', 1),\n",
       " ('soap', 'sope', 2),\n",
       " ('gave', 'cave', 1),\n",
       " ('never', 'knver', 2),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('killed', 'kild', 2),\n",
       " ('wait', 'wate', 2),\n",
       " ('inject', 'injeck', 1),\n",
       " ('make', 'mack', 2),\n",
       " ('sure', 'shore', 2),\n",
       " ('dry', 'drye', 1),\n",
       " ('fork', 'falk', 2),\n",
       " ('knock', 'nock', 1),\n",
       " ('themselves', 'them souve', 4),\n",
       " ('them', 'the', 1),\n",
       " ('worm', 'worme', 1),\n",
       " ('powder', 'pouder', 1),\n",
       " ('worm', 'worme', 1),\n",
       " ('get', 'ge', 1),\n",
       " ('their', 'there', 2),\n",
       " ('them', 'theme', 1),\n",
       " ('keep', 'geep', 1),\n",
       " ('sure', 'shore', 2),\n",
       " ('has', 'as', 1),\n",
       " ('enough', 'a nougth', 3),\n",
       " ('can', 'came', 2),\n",
       " ('for', 'of', 2),\n",
       " ('fattening', 'fating', 3),\n",
       " ('eat', 'eate', 1),\n",
       " ('bigger', 'biger', 1),\n",
       " ('fattening', 'fating', 3),\n",
       " ('when', 'whe', 1),\n",
       " ('ones', 'wones', 1),\n",
       " ('are', 'and', 2),\n",
       " ('big', 'bing', 1),\n",
       " ('weighing', 'waying', 4),\n",
       " ('weighed', 'waid', 4),\n",
       " ('ready', 'reddy', 1),\n",
       " ('killed', 'kild', 2),\n",
       " ('too', 'to', 1),\n",
       " ('Him', 'Im', 2),\n",
       " ('Him', 'Im', 2),\n",
       " ('too', 'to', 1),\n",
       " ('for', 'fro', 2),\n",
       " ('they', 'the', 1),\n",
       " ('too', 'to', 1),\n",
       " ('Troy', 'Toy', 1),\n",
       " ('thought', 'though', 1),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('fast', 'farst', 1),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('?', 'Consulatoin', 11),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('Japanese', 'Japannese', 1),\n",
       " ('Honda', 'Hondor', 2),\n",
       " ('fast', 'farst', 1),\n",
       " ('getting', 'geting', 1),\n",
       " ('his', 'is', 1),\n",
       " ('leg', 'lege', 1),\n",
       " ('another', 'a nouther', 2),\n",
       " ('hurt', 'hearte', 3),\n",
       " ('his', 'is', 1),\n",
       " (\"don't\", 'dont', 1),\n",
       " ('think', 'thing', 1),\n",
       " ('saw', 'sow', 1),\n",
       " ('sidecar', 'side car', 1),\n",
       " ('turn', 'turne', 1),\n",
       " ('sidecar', 'side care', 2),\n",
       " ('motorbike', 'motor bike', 1),\n",
       " (\"don't\", 'dont', 1),\n",
       " ('know', 'no', 2),\n",
       " ('happened', 'hapend', 2),\n",
       " ('hurt', 'heart', 2),\n",
       " ('motorbike', 'moter bike', 2),\n",
       " ('spun', 'spund', 1),\n",
       " ('motorbike', 'moter bike', 2),\n",
       " ('caught', 'caugh', 1),\n",
       " ('blew', 'blow', 1),\n",
       " ('petrol', 'petal', 2),\n",
       " ('soon', 'sone', 2),\n",
       " ('There', 'They', 2),\n",
       " ('final', 'fianl', 2),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('Honda', 'Hondor', 2),\n",
       " ('Triumph', 'Triumh', 1),\n",
       " (\"they're\", 'there', 2),\n",
       " ('Triumph', 'trumh', 3),\n",
       " ('Honda', 'Hondor', 2),\n",
       " ('going', 'go', 3),\n",
       " (\"he's\", 'his', 2),\n",
       " ('won', 'one', 2),\n",
       " ('Royal', 'Royl', 1),\n",
       " ('Honda', 'Hondor', 2),\n",
       " ('shone', 'shon', 1),\n",
       " ('ploughed', 'ploud', 3),\n",
       " ('done', 'don', 1),\n",
       " ('a', 'an', 1),\n",
       " ('had', 'hade', 1),\n",
       " ('cleaned', 'cleand', 1),\n",
       " ('for', 'fore', 1),\n",
       " ('potatoes', 'potato', 2),\n",
       " ('pathway', 'parth way', 2),\n",
       " ('ploughed', 'ploud', 3),\n",
       " ('heavy', 'hevey', 2),\n",
       " ('like', 'look', 3),\n",
       " ('pearls', 'pirls', 2),\n",
       " ('nearly', 'nealy', 1),\n",
       " ('touched', 'toch', 3),\n",
       " ('piece', 'pice', 1),\n",
       " ('cleaned', 'cleand', 1),\n",
       " ('break', 'brack', 2),\n",
       " ('hopped', 'hop', 3),\n",
       " ('popped', 'poped', 1),\n",
       " ('whistled', 'wisheld', 4),\n",
       " ('chirped', 'cherped', 1),\n",
       " ('tried', 'trid', 1),\n",
       " ('catch', 'chach', 2),\n",
       " ('bird', 'brid', 2),\n",
       " ('bird', 'brid', 2),\n",
       " ('know', 'no', 2),\n",
       " (\"can't\", \"carn't\", 1),\n",
       " ('know', 'no', 2),\n",
       " (\"we're\", 'were', 1),\n",
       " ('wanted', 'whanted', 1),\n",
       " (\"you're\", 'your', 2),\n",
       " ('wanted', 'whated', 2),\n",
       " ('Goodbye', 'Good by', 2),\n",
       " ('leaves', 'leavs', 1),\n",
       " ('apples', 'apple', 1),\n",
       " ('autumn', 'Aount', 5),\n",
       " ('you', 'yow', 1),\n",
       " ('cores', 'corres', 1),\n",
       " ('cores', 'corres', 1),\n",
       " ('you', 'yow', 1),\n",
       " ('throw', 'thorght', 4),\n",
       " ('cores', 'corres', 1),\n",
       " ('burn', 'brun', 2),\n",
       " ('orchard', 'orcher', 2),\n",
       " ('climb', 'clim', 1),\n",
       " ('them', 'then', 1),\n",
       " ('them', 'then', 1),\n",
       " ('earwigs', 'eyewigs', 2),\n",
       " ('their', 'there', 2),\n",
       " ('pockets', 'pocket', 1),\n",
       " ('apples', 'apple', 1),\n",
       " ('full', 'fall', 1),\n",
       " ('apples', 'apple', 1),\n",
       " ('them', 'then', 1),\n",
       " ('hanging', 'haing', 2),\n",
       " ('them', 'then', 1),\n",
       " ('them', 'then', 1),\n",
       " ('want', 'whant', 1),\n",
       " ('hairdresser', 'hair dreser', 2),\n",
       " ('want', 'whant', 1),\n",
       " ('want', 'whont', 2),\n",
       " ('married', 'marryid', 2),\n",
       " ('twenty one', 'twentone', 2),\n",
       " ('husband', 'husbon', 2),\n",
       " ('take', 'tack', 2),\n",
       " ('want', 'whant', 1),\n",
       " ('want', 'whant', 1),\n",
       " ('want', 'whont', 2),\n",
       " ('Butlins', 'butlins', 1),\n",
       " ('honeymoon', 'hunemoon', 2),\n",
       " ('sculpture', 'sculptor', 2),\n",
       " ('model', 'modal', 1),\n",
       " ('thing', 'think', 1),\n",
       " ('model', 'modal', 1),\n",
       " ('standing', 'staning', 1),\n",
       " ('modelled', 'malod', 5),\n",
       " ('model', 'molad', 3),\n",
       " ('thing', 'think', 1),\n",
       " ('calmer', 'comer', 2),\n",
       " ('carefully', 'caresll', 3),\n",
       " ('people', 'peolpe', 2),\n",
       " ('cruel', 'corller', 4),\n",
       " ('catch', 'cash', 2),\n",
       " ('their', 'there', 2),\n",
       " ('carrying', 'carring', 1),\n",
       " ('one', 'on', 1),\n",
       " ('Wings', 'Wing', 1),\n",
       " ('break', 'brick', 2),\n",
       " (\"man's\", 'mans', 1),\n",
       " ('swans', 'swan', 1),\n",
       " ('delicate', 'dellitent', 5),\n",
       " ('things', 'think', 2),\n",
       " ('Poem', 'Pome', 2),\n",
       " (\"daren't\", 'darnt', 2),\n",
       " (\"didn't\", 'dident', 2),\n",
       " ('quietly', 'quitely', 2),\n",
       " ('Their', 'There', 2),\n",
       " ('beating', 'beting', 1),\n",
       " ('rapidly', 'raperly', 2),\n",
       " (\"I'm\", 'I', 2),\n",
       " ('MARY', 'MARRY', 1),\n",
       " ('here', 'hear', 2),\n",
       " ('make', 'mack', 2),\n",
       " (\"What's\", 'What', 2),\n",
       " ('wrong', 'wong', 1),\n",
       " ('MARY', 'MARRY', 1),\n",
       " ('taking', 'thaing', 2),\n",
       " ('out', 'owt', 1),\n",
       " ('tonight', 'to night', 1),\n",
       " ('MARY', 'MARRY', 1),\n",
       " (\"it's\", 'it', 2),\n",
       " ('fault', 'falt', 1),\n",
       " (\"it's\", 'its', 1),\n",
       " ('fault', 'falt', 1),\n",
       " ('trying', 'traing', 1),\n",
       " ('MARY', 'MARRY', 1),\n",
       " (\"you've\", 'you', 3),\n",
       " ('choosing', 'ching', 3),\n",
       " ('better', 'bet', 3),\n",
       " (\"there's\", 'theres', 1),\n",
       " (\"What's\", 'What', 2),\n",
       " ('slammed', 'slander', 3),\n",
       " (\"can't\", 'carnt', 2),\n",
       " ('talk', 'tallk', 1),\n",
       " ('decision', 'disson', 3),\n",
       " ('instance', 'instead', 4),\n",
       " (\"there's\", 'theres', 1),\n",
       " (\"There's\", 'There', 2),\n",
       " ('no', 'on', 2),\n",
       " ('else', 'eles', 2),\n",
       " ('is', 'us', 1),\n",
       " (\"it's\", 'its', 1),\n",
       " ('trying', 'trining', 2),\n",
       " ('then', 'them', 1),\n",
       " ('rough', 'rought', 1),\n",
       " ('scream', 'scem', 2),\n",
       " ('scares', 'scards', 1),\n",
       " ('warned', 'wornd', 2),\n",
       " ('you', 'yew', 2),\n",
       " ('you', 'yow', 1),\n",
       " ('you', 'yow', 1),\n",
       " ('want', 'whant', 1),\n",
       " ('hurt', 'hert', 1),\n",
       " ('hurt', 'hert', 1),\n",
       " (\"you're\", 'yow', 4),\n",
       " ('wrong', 'rong', 1),\n",
       " ('you', 'yow', 1),\n",
       " ('any', 'eney', 2),\n",
       " ('you', 'yow', 1),\n",
       " ('tonight', 'to night', 1),\n",
       " ('know', 'no', 2),\n",
       " ('you', 'yow', 1),\n",
       " (\"o'clock\", 'o, clock', 2),\n",
       " (\"You're\", 'Your', 2),\n",
       " (\"don't\", 'dont', 1),\n",
       " ('know', 'no', 2),\n",
       " ('goodbye', 'goodby', 1),\n",
       " ('tonight', 'to night', 1),\n",
       " ('character', 'charickter', 2),\n",
       " ('Their', 'There', 2),\n",
       " ('their', 'there', 2),\n",
       " ('you', 'yow', 1),\n",
       " ('who', 'how', 2),\n",
       " ('asking', 'arsking', 1),\n",
       " ('you', 'yow', 1),\n",
       " ('else', 'els', 1),\n",
       " (\"you'll\", 'your', 3),\n",
       " ('yourself', 'your self', 1),\n",
       " ('enough', 'engouh', 2),\n",
       " (\"you'll\", 'your', 3),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('enough', 'engouh', 2),\n",
       " (\"I'll\", 'I', 3),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('upstairs', 'up stairs', 1),\n",
       " (\"She's\", 'She', 2),\n",
       " ('whatever', 'what ever', 1),\n",
       " ('happens', 'happends', 1),\n",
       " (\"boyfriend's\", 'boyfrends', 2),\n",
       " ('opened', 'opend', 1),\n",
       " ('here', 'hear', 2),\n",
       " ('So', 'Show', 2),\n",
       " ('have', 'has', 2),\n",
       " (\"Let's\", 'Lets', 1),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('want', 'whont', 2),\n",
       " (\"let's\", 'lets', 1),\n",
       " ('something', 'somethink', 1),\n",
       " ('happily', 'happly', 1),\n",
       " ('you', 'yow', 1),\n",
       " ('story', 'stors', 1),\n",
       " ('works', 'work', 1),\n",
       " ('factory', 'factoy', 1),\n",
       " ('works', 'wors', 1),\n",
       " ('?', 'nsor', 4),\n",
       " ('Watson', 'watston', 2),\n",
       " ('works', 'wonrs', 2),\n",
       " ('greenhouse', 'gnenhouen', 4),\n",
       " ('excited', 'exited', 1),\n",
       " ('went', 'wetn', 2),\n",
       " ('to', 'two', 1),\n",
       " ('His', 'He', 2),\n",
       " ('mother', 'mouthr', 2),\n",
       " ('said', 'sald', 1),\n",
       " ('?', 'nis', 3),\n",
       " ('sneaking', 'sneking', 1),\n",
       " ('teddy boy', 'tedeboy', 3),\n",
       " ('sneaking', 'sneking', 1),\n",
       " ('to', 'two', 1),\n",
       " ('waited', 'wated', 1),\n",
       " ('teddy boy', 'tedeboy', 3),\n",
       " ('teddy boy', 'tedeboy', 3),\n",
       " ('came', 'kom', 3),\n",
       " ('outside', 'out sild', 3),\n",
       " ('sneaking', 'sneking', 1),\n",
       " ('Teddy boy', 'Tedeboy', 3),\n",
       " ('teddy boy', 'tedeboy', 3),\n",
       " ('One', 'Won', 3),\n",
       " ('farmer', 'frm', 3),\n",
       " ('for', 'four', 1),\n",
       " ('vet', 'vethn', 2),\n",
       " (\"wasn't\", \"whdn't\", 2),\n",
       " ('healthy', 'hethy', 2),\n",
       " ('and', 'an', 1),\n",
       " ('fit', 'fanit', 2),\n",
       " ('farmer', 'frm', 3),\n",
       " ('said', 'sidn', 2),\n",
       " ('vet', 'vethn', 2),\n",
       " ('unhealthy', 'on hethy', 4),\n",
       " ('vet', 'vethu', 2),\n",
       " ('said', 'sidn', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('come', 'kumh', 3),\n",
       " ('old', 'lod', 2),\n",
       " ('said', 'sidn', 2),\n",
       " ('vet', 'vethn', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('to', 'two', 1),\n",
       " ('old', 'lod', 2),\n",
       " ('vet', 'vethn', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('old', 'lod', 2),\n",
       " ('said', 'sidn', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('farm', 'frm', 1),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('out', 'ouht', 1),\n",
       " ('laid', 'ladh', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('too', 'two', 1),\n",
       " ('behind', 'behism', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('his', 'he', 2),\n",
       " ('?', 'bav', 3),\n",
       " ('two', 'to', 1),\n",
       " ('lay', 'ladh', 2),\n",
       " ('vet', 'vetin', 2),\n",
       " ('vet', 'vent', 1),\n",
       " ('what', 'wat', 1),\n",
       " ('wrong', 'ron', 2),\n",
       " ('with', 'wis', 2),\n",
       " ('sleep', 'seph', 3),\n",
       " ('vet', 'vethn', 2),\n",
       " ('to', 'two', 1),\n",
       " (\"farmer's\", 'frmh', 5),\n",
       " ('vet', 'vethn', 2),\n",
       " ('farmer', 'framh', 4),\n",
       " ('vet', 'vethn', 2),\n",
       " ('said', 'sidn', 2),\n",
       " ('to', 'two', 1),\n",
       " ('asleep', 'a seph', 4),\n",
       " ('vet', 'vethn', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('?', 'sechrus', 7),\n",
       " (\"pigs'\", 'pigs', 1),\n",
       " ('laid', 'ladh', 2),\n",
       " ('sleep', 'seph', 3),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('vet', 'vethn', 2),\n",
       " ('back', 'bakh', 2),\n",
       " ('farmer', 'frmh', 3),\n",
       " ('went', 'weth', 2),\n",
       " ('?', 'ruth', 4),\n",
       " ('?', 'humit', 5),\n",
       " ('woke', 'wok', 1),\n",
       " ('better', 'beththe', 3),\n",
       " ('End', 'And', 1),\n",
       " ('you', 'your', 1),\n",
       " ('hands', 'hand', 1),\n",
       " ('sing', 'sings', 1),\n",
       " ('done', 'don', 1),\n",
       " ('our', 'ous', 1),\n",
       " ('the', 'ge', 2),\n",
       " ('sun', 'son', 1),\n",
       " ('And', 'Ane', 1),\n",
       " ('Teddy boy', 'Teddoy', 3),\n",
       " ('start', 'starte', 1),\n",
       " ('trouble', 'troefle', 2),\n",
       " ('teddy boy', 'teddoy', 3),\n",
       " ('Teddy boy', 'Teddoy', 3),\n",
       " ('round', 'rownd', 1),\n",
       " ('Teddy boy', 'Teddoy', 3),\n",
       " ('to', 'two', 1),\n",
       " ('pictures', 'pictyres', 1),\n",
       " ('manager', 'maneger', 1),\n",
       " ('stairs', 'stars', 1),\n",
       " ('woman', 'women', 1),\n",
       " ('she', 'he', 1),\n",
       " ('?', 'Hurbured', 8),\n",
       " ('landed', 'laded', 1),\n",
       " ('kitchen', 'kitching', 2),\n",
       " ('meadow', 'meadoy', 1),\n",
       " ('confide', 'cornfield', 4),\n",
       " ('daffodils', 'daffodill', 1),\n",
       " ('?', 'crowsed', 7),\n",
       " ('head', 'hed', 1),\n",
       " ('was', 'wos', 1),\n",
       " ('teddy boys', 'teddyboys', 1),\n",
       " ('big-headed', 'Big  haded', 4),\n",
       " ('want', 'wat', 1),\n",
       " ('Teddy boys', 'Taddyboys', 2),\n",
       " ('about', 'a Bat', 3),\n",
       " ('knife', 'kniffe', 1),\n",
       " ('shop', 'shap', 1),\n",
       " ('cafe', 'kiffe', 3),\n",
       " ('to', 'two', 1),\n",
       " ('to', 'two', 1),\n",
       " ('teddy boys', 'teddyboys', 1),\n",
       " ('knife', 'kiffe', 2),\n",
       " ('too', 'two', 1),\n",
       " ('dangerous', 'dangers', 2),\n",
       " ('they', 'the', 1),\n",
       " ('trying', 'try', 3),\n",
       " ('car', 'Star', 2),\n",
       " ('questioned', 'question', 2),\n",
       " ('End', 'ANd', 2),\n",
       " ('died', 'ded', 1),\n",
       " ('him', 'hm', 1),\n",
       " ('himself', 'his self', 2),\n",
       " ('End', 'ANd', 2),\n",
       " ('story', 'hio', 4),\n",
       " ('steal', 'still', 2),\n",
       " ('cops', 'caps', 1),\n",
       " ('and', 'an', 1),\n",
       " ('cops', 'caps', 1),\n",
       " ('came', 'kum', 3),\n",
       " ('End', 'And', 1),\n",
       " ('story', 'shio', 4),\n",
       " ('sweets', 'swet', 2),\n",
       " ('was', 'wos', 1),\n",
       " ('waiting', 'waten', 3),\n",
       " ('guilty', 'guilt', 1),\n",
       " ('End', 'ANd', 2),\n",
       " ('police', 'polic', 1),\n",
       " ('police', 'polic', 1),\n",
       " ('came', 'cam', 1),\n",
       " ('police', 'polic', 1),\n",
       " ('went', 'wen', 1),\n",
       " ('see', 'se', 1),\n",
       " ('her', 'She', 2),\n",
       " ('went', 'wen', 1),\n",
       " ('it', 'she', 3),\n",
       " ('time', 'tim', 1),\n",
       " ('come', 'coum', 2),\n",
       " ('End', 'And', 1),\n",
       " ('to', 'two', 1),\n",
       " ('man', 'mae', 1),\n",
       " ('to', 'two', 1),\n",
       " ('Police', 'Pollce', 1),\n",
       " ('did', 'ded', 1),\n",
       " ('old', 'lod', 2),\n",
       " ('for', 'four', 1),\n",
       " ('murdered', 'murbur', 4),\n",
       " ('murder', 'murber', 1),\n",
       " ('End', 'And', 1),\n",
       " ('story', 'shio', 4),\n",
       " ('tramps', 'trmp', 2),\n",
       " ('tramp', 'trmp', 1),\n",
       " ('road', 'rod', 1),\n",
       " ('tramp', 'trmp', 1),\n",
       " ('tramp', 'trmp', 1),\n",
       " ('what', 'wat', 1),\n",
       " ('want', 'woth', 3),\n",
       " ('said', 'sald', 1),\n",
       " ('tramp', 'trmp', 1),\n",
       " ('eyes', 'eyey', 1),\n",
       " ('he', 'the', 1),\n",
       " ('followed', 'fellowed', 1),\n",
       " ('said', 'sid', 1),\n",
       " ('home', 'hom', 1),\n",
       " ('said', 'sid', 1),\n",
       " ('said', 'sid', 1),\n",
       " ('End', 'And', 1),\n",
       " ('locked', 'lockEd', 1),\n",
       " ('road', 'rad', 1),\n",
       " ('man', 'manh', 1),\n",
       " ('man', 'manh', 1),\n",
       " ('man', 'mand', 1),\n",
       " ('his', 'he', 2),\n",
       " ('standard', 'stardnd', 3),\n",
       " ('ten', 'tan', 1),\n",
       " ('Yard', 'Ysid', 2),\n",
       " ('End', 'And', 1),\n",
       " (\"Tom's\", 'Toms', 1),\n",
       " ('stinks', 'sticks', 1),\n",
       " ('mother', 'morther', 1),\n",
       " ('trashy', 'tashie', 3),\n",
       " ('field', 'fed', 2),\n",
       " ('fish', 'fsh', 1),\n",
       " ('air', 'hare', 3),\n",
       " ('water-rat', 'waterrat', 1),\n",
       " ('field', 'fed', 2),\n",
       " ('to', 'two', 1),\n",
       " ('school', 'shool', 1),\n",
       " ('come', 'com', 1),\n",
       " ('sea', 'see', 1),\n",
       " ('sea', 'see', 1),\n",
       " ('sea', 'see', 1),\n",
       " ('sea', 'see', 1),\n",
       " ('feet', 'fet', 1),\n",
       " ('to', 'two', 1),\n",
       " ('Porky', 'Paulkey', 4),\n",
       " ('to', 'two', 1),\n",
       " ('he', 'the', 1),\n",
       " ('ambulance', 'amblance', 1),\n",
       " ('to', 'tow', 1),\n",
       " ('to', 'two', 1),\n",
       " ('dying', 'dieing', 2),\n",
       " ('home', 'homse', 1),\n",
       " ('to', 'two', 1),\n",
       " ('door', 'boor', 1),\n",
       " ('to', 'qu', 2),\n",
       " ('wall', 'molh', 3),\n",
       " ('roof', 'rhfn', 3),\n",
       " ('chimney', 'cimbenr', 4),\n",
       " ('fire', 'fiar', 2),\n",
       " ('jumped', 'jumth', 3),\n",
       " ('his', 'he', 2),\n",
       " ('seat', 'sat', 1),\n",
       " ('over', 'ove', 1),\n",
       " ('out', 'ou', 1),\n",
       " ('to', 'two', 1),\n",
       " ('wall', 'wah', 2),\n",
       " ('to', 'two', 1),\n",
       " ('the', 'he', 1),\n",
       " ('went', 'wens', 1),\n",
       " ('army', 'hrmehr', 4),\n",
       " (\"didn't\", 'denat', 3),\n",
       " ('like', 'lichr', 3),\n",
       " ('army', 'hrmehn', 4),\n",
       " ('leave', 'lefnr', 3),\n",
       " (\"didn't\", 'dednt', 2),\n",
       " ('come', 'comr', 1),\n",
       " ('douche', 'back', 5),\n",
       " ('by', 'bihr', 3),\n",
       " ('captain', 'cpn', 4),\n",
       " ('said', 'sedn', 3),\n",
       " ('back', 'doc', 3),\n",
       " ('yet', 'yeth', 1),\n",
       " ('down', 'dus', 3),\n",
       " ('?', 'unz', 3),\n",
       " ('road', 'rod', 1),\n",
       " ('London', 'Londod', 1),\n",
       " ('think', 'thank', 1),\n",
       " ('think', 'tink', 1),\n",
       " ('idea', 'ida', 1),\n",
       " ('yours', 'yourns', 1),\n",
       " ('circus', 'sercus', 2),\n",
       " ('around', 'a round', 1),\n",
       " ('pointing', 'pooting', 2),\n",
       " ('meadow', 'medow', 1),\n",
       " ('road', 'raod', 2),\n",
       " ('siren', 'satren', 2),\n",
       " ('hammering', 'hemmsering', 2),\n",
       " ('many', 'meny', 1),\n",
       " ('metals', 'metet', 3),\n",
       " ('or', 'ot', 1),\n",
       " ('dance', 'dane', 1),\n",
       " ('young', 'yung', 1),\n",
       " ('peep', 'peope', 2),\n",
       " ('dancing', 'pncing', 2),\n",
       " ('?', 'anetes', 6),\n",
       " ('got', 'gnt', 1),\n",
       " ('There', 'They', 2),\n",
       " (\"dad's\", 'dads', 1),\n",
       " (\"mum's\", 'mums', 1),\n",
       " ('married', 'marrede', 2),\n",
       " ('months', 'month', 1),\n",
       " ('company', 'coperney', 4),\n",
       " ('person', 'peason', 1),\n",
       " ('picked', 'picted', 1),\n",
       " ('says', 'sais', 1),\n",
       " ('says', 'seis', 2),\n",
       " ('says', 'sais', 1),\n",
       " ('says', 'sais', 1),\n",
       " ('Sylvia', 'sylver', 3),\n",
       " ('Sylvia', 'Sylver', 2),\n",
       " ('says', 'sais', 1),\n",
       " ('no one', 'now one', 1),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('Macwilliams', 'macwillaims', 3),\n",
       " ('pulled', 'pull', 2),\n",
       " ('which', 'witch', 2),\n",
       " ('kitchen', 'kichen', 1),\n",
       " ('threw', 'frow', 3),\n",
       " ('Macwilliams', 'macwillaims', 3),\n",
       " ('forward', 'forword', 1),\n",
       " ('almighty', 'almity', 2),\n",
       " ('died', 'diad', 1),\n",
       " ('lived', 'lifd', 2),\n",
       " ('council', 'counsel', 2),\n",
       " ('outside', 'out side', 1),\n",
       " ('London', 'Londen', 1),\n",
       " ('went', 'whenet', 2),\n",
       " ('fighting', 'figthing', 2),\n",
       " ('grown', 'groon', 1),\n",
       " ('Joan', 'Jone', 2),\n",
       " ('too', 'to', 1),\n",
       " ('nevertheless', 'never the less', 2),\n",
       " ('died', 'diad', 1),\n",
       " ('there', 'they', 2),\n",
       " ('of', 'off', 1),\n",
       " ('slowly', 'slolly', 1),\n",
       " ('stopped', 'stoped', 1),\n",
       " ('until', 'untill', 1),\n",
       " ('had', 'have', 2),\n",
       " ('he', 'his', 2),\n",
       " ('carried', 'carred', 1),\n",
       " ('be', 'me', 1),\n",
       " ('destroyed', 'distrod', 3),\n",
       " ('baths', 'bath', 1),\n",
       " ('clean', 'clearn', 1),\n",
       " (\"I'm\", 'Im', 1),\n",
       " ('allowed', 'alloud', 2),\n",
       " ('programmes', 'programes', 1),\n",
       " ('suitable', 'surtebull', 4),\n",
       " ('there', 'they', 2),\n",
       " ('unfit', 'unfitt', 1),\n",
       " ('others', 'other', 1),\n",
       " ('stabbed', 'stabed', 1),\n",
       " ('of', 'off', 1),\n",
       " ('boasting', 'bosting', 1),\n",
       " ('paid', 'payed', 2),\n",
       " ('employment', 'imployment', 1),\n",
       " ('sitting', 'siting', 1),\n",
       " ('stuffy', 'stufy', 1),\n",
       " ('apprenticeship', 'apprentiship', 2),\n",
       " ('classes', 'classis', 1),\n",
       " ('once', 'ones', 2),\n",
       " ('useful', 'usfull', 2),\n",
       " ('While', 'Will', 2),\n",
       " ('getting', 'get', 4),\n",
       " ('shillings', 'shilling', 1),\n",
       " ('Apprenticeship', 'Apprentiship', 2),\n",
       " ('of', 'off', 1),\n",
       " ('chosen', 'choosen', 1),\n",
       " ('career', 'carrer', 1),\n",
       " ('different', 'diffrent', 1),\n",
       " ('anything', 'enthing', 2),\n",
       " ('working', 'work', 3),\n",
       " ('given', 'give', 1),\n",
       " ('leave', 'life', 3),\n",
       " ('wants', 'want', 1),\n",
       " ('always', 'all ways', 2),\n",
       " ('do', 'done', 2),\n",
       " ('sometimes', 'some thime', 3),\n",
       " ('yours', 'you', 2),\n",
       " ('There', 'They', 2),\n",
       " ('and', 'a', 2),\n",
       " ('brothers', 'brother', 1),\n",
       " ('sisters', 'sister', 1),\n",
       " ('comes', 'come', 1),\n",
       " ('?', 'Half-hose', 9),\n",
       " ('likes', 'like', 1),\n",
       " ('wavy', 'wavey', 1),\n",
       " ('boyfriend', 'boyfrend', 1),\n",
       " ('hates', 'hate', 1),\n",
       " ('prayer-book', 'prayerbook', 1),\n",
       " ('colour', 'colur', 1),\n",
       " ('clothes', 'colhes', 2),\n",
       " ('dense', 'dence', 1),\n",
       " ('CHARACTERS', 'CHARTORS', 3),\n",
       " ('asks', 'ask', 1),\n",
       " (\"boy's\", 'boys', 1),\n",
       " (\"haven't\", \"haven's\", 1),\n",
       " ('prettiest', 'prettest', 1),\n",
       " ('answered', 'anwerd', 2),\n",
       " ('asked', 'ask', 2),\n",
       " ('her', 'he', 1),\n",
       " ('here', 'hear', 2),\n",
       " ('comes', 'come', 1),\n",
       " (\"Whoever's\", 'Whos evers', 3),\n",
       " (\"Jean's\", 'jeans', 2),\n",
       " ('Cheerio', 'Cheere ho', 3),\n",
       " (\"Joyce's\", 'Joyce', 2),\n",
       " ('parents', 'prarents', 1),\n",
       " (\"whoever's\", 'who evers', 2),\n",
       " ('parents', 'prerents', 2),\n",
       " ('go', 'do', 1),\n",
       " ('pictures', 'picture', 1),\n",
       " ('walked', 'walk', 2),\n",
       " (\"Jean's\", 'Jeans', 1),\n",
       " ('he', 'the', 1),\n",
       " ('Roy', 'Roys', 1),\n",
       " (\"o'clock\", 'O clock', 2),\n",
       " ('their', 'they', 2),\n",
       " ('cheerio', 'cheeroh', 2),\n",
       " (\"don't\", 'want', 3),\n",
       " ('the', 'they', 1),\n",
       " ('their', 'there', 2),\n",
       " ('got', 'go', 1),\n",
       " (\"wasn't\", 'wasnt', 1),\n",
       " ('myself', 'my shelf', 2),\n",
       " ('stopped', 'stop', 3),\n",
       " (\"Joyce's\", 'Joyce', 2),\n",
       " ('Motorbike', 'Motor-bikes', 2),\n",
       " ('they', 'there', 2),\n",
       " ('night', 'tonight', 2),\n",
       " ('went', 'sent', 1),\n",
       " ('over', 'ove', 1),\n",
       " (\"John's\", 'John', 2),\n",
       " ('introduced', 'introducted', 1),\n",
       " ('decided', 'dicide', 2),\n",
       " ('Married', 'Marrid', 1),\n",
       " ('special', 'spicil', 2),\n",
       " ('the', 'they', 1),\n",
       " ('Their', 'There', 2),\n",
       " ('engagement', 'enagement', 1),\n",
       " ('engaged', 'enaged', 1),\n",
       " ('presents', 'present', 1),\n",
       " ('too', 'two', 1),\n",
       " ('the', 'they', 1),\n",
       " ('walked', 'walk', 2),\n",
       " ('their', 'they', 2),\n",
       " ('their', 'they', 2),\n",
       " ('decided', 'decider', 1),\n",
       " ('children', 'chidren', 1),\n",
       " (\"Adam's\", 'Adam', 2),\n",
       " ('what', 'want', 2),\n",
       " (\"don't\", 'don', 2),\n",
       " ('beverley', 'beverly', 1),\n",
       " ('sisters', 'sister', 1),\n",
       " ('know', 'no', 2),\n",
       " ('beverley', 'beverly', 1),\n",
       " ('beverley', 'beverly', 1),\n",
       " ('drunk', 'druck', 1),\n",
       " ('things', 'thinks', 1),\n",
       " ('was', 'we', 2),\n",
       " ('painted', 'panted', 1),\n",
       " ('outside', 'out side', 1),\n",
       " ('happening', 'happing', 2),\n",
       " ('fashioned', 'fashion', 2),\n",
       " ('Their', 'They', 2),\n",
       " ('their', 'they', 2),\n",
       " (\"grandpa's\", 'grandpas', 1),\n",
       " ('outside', 'out side', 1),\n",
       " ('His', \"He's\", 2),\n",
       " ('meant', \"mean't\", 1),\n",
       " ('and', 'a', 2),\n",
       " ('where', 'were', 1),\n",
       " ('your', 'you', 1),\n",
       " ('mother', 'mothers', 1),\n",
       " ('has', 'as', 1),\n",
       " ('its', \"it's\", 1),\n",
       " ('walked', 'walk', 2),\n",
       " ('babies', 'babys', 2),\n",
       " ('and', 'a', 2),\n",
       " ('asleep', 'a sleep', 1),\n",
       " ('baby', 'babys', 1),\n",
       " ('door', 'down', 2),\n",
       " ('saw', 'sow', 1),\n",
       " ('phoned', 'phone', 1),\n",
       " ('minutes', 'minetes', 1),\n",
       " ('outside', 'out side', 1),\n",
       " ('and', 'aud', 1),\n",
       " ('them', 'then', 1),\n",
       " ('after a while', 'afterawhile', 2),\n",
       " ('woman', 'women', 1),\n",
       " ('policemen', 'polce men', 2),\n",
       " ('woman', 'women', 1),\n",
       " ('grabbed', 'grab', 3),\n",
       " ('pounds', 'ponds', 1),\n",
       " ('pounds', 'ponud', 3),\n",
       " ('always', 'all ways', 2),\n",
       " ('wherever', 'were ever', 3),\n",
       " ('there', 'the', 2),\n",
       " ('until', 'untill', 1),\n",
       " ('his', \"he's\", 2),\n",
       " (\"girl's\", 'girls', 1),\n",
       " ('altar', 'alter', 1),\n",
       " ('boyfriend', 'boy friend', 1),\n",
       " ('tied', 'tired', 1),\n",
       " ('themselves', 'they self', 5),\n",
       " ('their', 'they', 2),\n",
       " ('happened', 'happen', 2),\n",
       " ('pregnant', 'pregant', 1),\n",
       " ('their', 'they', 2),\n",
       " ('families', 'familys', 2),\n",
       " ('careful', 'carefull', 1),\n",
       " ('apples', 'apple', 1),\n",
       " ('too', 'to', 1),\n",
       " ('especially', 'a specally', 3),\n",
       " ('careful', 'carful', 1),\n",
       " ('wherever', 'where ever', 2),\n",
       " ('someone', 'some one', 1),\n",
       " ('barbed', 'barb', 2),\n",
       " ('probably', 'probally', 1),\n",
       " ('they', 'the', 1),\n",
       " ('say', 'said', 2),\n",
       " ('recognized', 'reconnised', 2),\n",
       " ('another', 'a nother', 1),\n",
       " ('Stranded', 'Stranden', 1),\n",
       " ('midsummer', \"midsummer's\", 2),\n",
       " ('coral', 'corral', 1),\n",
       " ('outfits', 'out fits', 1),\n",
       " ('volunteered', 'volonteered', 1),\n",
       " ('There', 'Their', 2),\n",
       " ('bodies', 'bodys', 2),\n",
       " ('shipwreck', 'ship wreck', 1),\n",
       " ('There', 'Their', 2),\n",
       " ('opened', 'open', 2),\n",
       " ('two', 'to', 1),\n",
       " ('then', 'the', 1),\n",
       " ('Lucky', 'Luckily', 2),\n",
       " ('tinned', 'tin', 3),\n",
       " ('lifeboat', 'life boat', 1),\n",
       " ('used', \"use't\", 2),\n",
       " ('usually', 'usally', 1),\n",
       " ('shortened', 'shortend', 1),\n",
       " ('down', 'done', 2),\n",
       " ('killed', 'kill', 2),\n",
       " ('ground', 'gound', 1),\n",
       " ('laid', 'laide', 1),\n",
       " ('as', 'ass', 1),\n",
       " ('evening', 'evining', 1),\n",
       " (\"father's\", \"farther's\", 1),\n",
       " ('reading', 'reding', 1),\n",
       " ('coat', 'cote', 2),\n",
       " ('hook', 'hock', 1),\n",
       " ('dark', 'dork', 1),\n",
       " ('GARDEN', 'GARDON', 1),\n",
       " ('Cheetah', 'Cheter', 3),\n",
       " ('cheetah', 'cheter', 3),\n",
       " ('prowls', 'prouls', 1),\n",
       " ('undergrowth', 'undergroth', 1),\n",
       " ('jungle', 'jungel', 2),\n",
       " ('clatter', 'clater', 1),\n",
       " ('their', 'there', 2),\n",
       " ('jungle', 'jungel', 2),\n",
       " ('Monkeys', 'Munces', 3),\n",
       " ('little', 'litel', 2),\n",
       " ('cheetah', 'cheter', 3),\n",
       " ('roars', 'rorse', 2),\n",
       " ('falls', 'forls', 2),\n",
       " ('cheetah', 'cheter', 3),\n",
       " ('caught', 'cort', 4),\n",
       " ('prey', 'pray', 1),\n",
       " ('Death', 'Dearth', 1),\n",
       " ('when', 'wen', 1),\n",
       " ('having', 'haveing', 1),\n",
       " ('breakfast', 'brecfast', 2),\n",
       " ('came', 'come', 1),\n",
       " ('bitten', 'biten', 1),\n",
       " (\"boy's\", 'boys', 1),\n",
       " ('Hong Kong', 'Honk Kong', 1),\n",
       " ('took', 'tuck', 2),\n",
       " ('houseboat', 'house boat', 1),\n",
       " ('thought', 'thort', 3),\n",
       " ('queer', 'quere', 2),\n",
       " ('houseboat', 'house boat', 1),\n",
       " ('were', 'where', 1),\n",
       " ('four', 'fore', 2),\n",
       " ('sitting', 'siting', 1),\n",
       " ('chair', 'chere', 3),\n",
       " ('where', 'were', 1),\n",
       " ('entered', 'enterd', 1),\n",
       " (\"that's\", 'thats', 1),\n",
       " ('what', 'wat', 1),\n",
       " ('bullet', 'bolot', 3),\n",
       " ('equipment', 'aquitment', 2),\n",
       " ('write', 'rite', 1),\n",
       " ('piece', 'pese', 2),\n",
       " ('what', 'wot', 2),\n",
       " ('need', 'nede', 2),\n",
       " ('of', 'on', 1),\n",
       " ('once', 'wons', 3),\n",
       " ('when', 'wen', 1),\n",
       " ('bullet', 'bulete', 2),\n",
       " ('wait', 'wat', 1),\n",
       " ('what', 'wot', 2),\n",
       " ('happened', 'hapends', 3),\n",
       " ('Outside', 'Out side', 1),\n",
       " ('missed', 'mist', 3),\n",
       " ('missed', 'mist', 3),\n",
       " ('too', 'to', 1),\n",
       " ('man', 'may', 1),\n",
       " ('stopped', 'stoped', 1),\n",
       " ('bullet', 'bulet', 1),\n",
       " ('took', 'tuck', 2),\n",
       " ('prison', 'prisin', 1),\n",
       " ('bullet', 'bulet', 1),\n",
       " ('suddenly', 'suddenel', 2),\n",
       " ('It', 'I', 1),\n",
       " ('had', 'has', 1),\n",
       " ('cane', 'cain', 2),\n",
       " ('teachers', 'teacher', 1),\n",
       " ('cane', 'cain', 2),\n",
       " ('Bicycle', 'Bicyle', 1),\n",
       " ('do not', 'donot', 1),\n",
       " ('wrong', 'rong', 1),\n",
       " ('father', 'farther', 1),\n",
       " ('Father', 'Farther', 1),\n",
       " ('sometimes', 'some time', 2),\n",
       " ('pair', 'per', 2),\n",
       " ('fly', 'fie', 2),\n",
       " ('and', 'a', 2),\n",
       " ('feet', 'fee', 1),\n",
       " ('cannot', 'can not', 1),\n",
       " ('flies', 'fies', 1),\n",
       " ('sexton', 'sixty one', 4),\n",
       " ('sows', 'sow', 1),\n",
       " ('know', 'no', 2),\n",
       " ('what', 'wot', 2),\n",
       " ('?', 'solued', 6),\n",
       " ('sore', 'saw', 3),\n",
       " ('foot-and-mouth', 'footandmouth', 2),\n",
       " ('killed', 'kid', 3),\n",
       " ('area', 'airaear', 3),\n",
       " ('stopped', 'stoped', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples_with_distance_list = get_distance(cor_mis_tuples_list)\n",
    "get_distance(tuples_with_distance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e677bc",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>B:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c514e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of errors with distance 1 is: 0.5540592535590612\n",
      "The percentage of errors with distance 2 is: 0.29857637552904964\n",
      "The percentage of errors with distance >2 is: 0.1473643709118892\n"
     ]
    }
   ],
   "source": [
    "mistake_per_1 = get_number_of_distance(tuples_with_distance_list,1,1) / (len(tuples_with_distance_list))\n",
    "mistake_per_2 = get_number_of_distance(tuples_with_distance_list,2,1) / (len(tuples_with_distance_list))\n",
    "mistake_per_bigger_than_2 = get_number_of_distance(tuples_with_distance_list,2,2) / (len(tuples_with_distance_list))\n",
    "\n",
    "print(\"The percentage of errors with distance 1 is: \" + str(mistake_per_1))\n",
    "print(\"The percentage of errors with distance 2 is: \" + str(mistake_per_2))\n",
    "print(\"The percentage of errors with distance >2 is: \" + str(mistake_per_bigger_than_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddfda9",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>The 10 most common errors in a file for any distance edit = 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c339ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('james', 'jame'), 21),\n",
       " (('too', 'to'), 20),\n",
       " ((\"don't\", 'dont'), 20),\n",
       " (('to', 'two'), 17),\n",
       " (('her', 'here'), 16),\n",
       " (('got', 'go'), 13),\n",
       " (('off', 'of'), 13),\n",
       " (('his', 'is'), 12),\n",
       " ((\"that's\", 'thats'), 11),\n",
       " ((\"it's\", 'its'), 11)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=FreqDist(get_list_by_distance(tuples_with_distance_list,1,1)) # make a list of freq\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fb5d5",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>The 10 most common errors in a file for any distance edit = 2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09da8762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('their', 'there'), 20),\n",
       " (('there', 'their'), 17),\n",
       " (('here', 'hear'), 10),\n",
       " (('know', 'no'), 9),\n",
       " (('vet', 'vethn'), 9),\n",
       " (('looked', 'look'), 8),\n",
       " ((\"you're\", 'your'), 7),\n",
       " (('their', 'they'), 7),\n",
       " (('there', 'they'), 6),\n",
       " (('farmer', 'farm'), 6)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=FreqDist(get_list_by_distance(tuples_with_distance_list,2,1)) # make a list of freq\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38681b78",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>The 10 most common errors in a file for any distance edit >2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30eeea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('farmer', 'frmh'), 10),\n",
       " (('stopped', 'stop'), 6),\n",
       " (('teddy boy', 'tedeboy'), 5),\n",
       " (('teddy boy', 'teddoy'), 4),\n",
       " (('cheetah', 'cheter'), 4),\n",
       " (('walked', 'wark'), 3),\n",
       " (('hutch', 'hudge'), 3),\n",
       " (('signpost', 'sine post'), 3),\n",
       " (('they', 'thrar'), 3),\n",
       " (('knocked', 'nock'), 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=FreqDist(get_list_by_distance(tuples_with_distance_list,2,2)) # make a list of freq\n",
    "fdist.most_common(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda7da2",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>C:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8646640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alternative_edit1(err_word): # the function get word and return alternative word with distance 1 from words.words libary\n",
    "    alternative_words=[]\n",
    "    for word in words.words():\n",
    "        if(nltk.edit_distance(err_word,word.lower()) == 1):\n",
    "            alternative_words.append(word.lower())\n",
    "    return alternative_words   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac26ce1",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>D:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347dff84",
   "metadata": {},
   "source": [
    "ב-50 הטעויות הראשונות יש כפילויות ולכן סך הכל יש 40 מילים שונות "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7deabd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_words = {}\n",
    "correct_word_exist = 0\n",
    "first_50_error_tuple = cor_mis_tuples_list[0:50]\n",
    "list_that_not_include = [] # רשימת המילים שהמילה הנכונה לא הופיעה במועמדים\n",
    "for error in first_50_error_tuple:\n",
    "    err_word = error[1].lower()\n",
    "    corr_word = error[0].lower()\n",
    "    if(err_word not in alternative_words.keys()):\n",
    "        alternative_words[err_word] = list(set(get_alternative_edit1(err_word))) # מכיוון שהפכנו את כל המילים לאותיות קטנות אז יש חזרות של מילים כאשר אחת עם אות קטנה והשנייה עם אות גדולה\n",
    "        if(corr_word in alternative_words[err_word]):\n",
    "            correct_word_exist += 1 # אם המילה נמצאת, מעלה את המונה\n",
    "        else:\n",
    "            list_that_not_include.append(err_word) # אחרת מוסיף אותה לרשימת המילים שלא היו ברשימה שלהן\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85821a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of candidates for each word is: 18.425\n",
      "The percentage of cases the correct word was included in the list 0.4%\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "list_mean = []\n",
    "\n",
    "for word_list in alternative_words.values():\n",
    "    list_mean.append(len(word_list))\n",
    "    \n",
    "print(\"The average of candidates for each word is: \" + str(statistics.mean(list_mean)))   \n",
    "print(\"The percentage of cases the correct word was included in the list \" + str(round((correct_word_exist/len(list_mean)),2)) +\"%\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cba1abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sister', 'siter'),\n",
       " ('sister', 'siter'),\n",
       " ('goes', 'go'),\n",
       " ('sometimes', 'some times'),\n",
       " ('sometimes', 'some times'),\n",
       " ('club', 'clob'),\n",
       " ('bellringing', 'bell ringing'),\n",
       " ('watch', 'wakh'),\n",
       " ('front', 'frount'),\n",
       " ('second', 'sexeon'),\n",
       " ('watch', 'wach'),\n",
       " ('watch', 'wach'),\n",
       " ('cowboys', 'cow Boys'),\n",
       " ('sometimes', 'some times'),\n",
       " ('club', 'colbe'),\n",
       " ('watch', 'wach'),\n",
       " ('watch', 'wach'),\n",
       " ('think', 'thing'),\n",
       " ('TV', 'tv'),\n",
       " ('square', 'squar'),\n",
       " ('eyes', 'iyes'),\n",
       " (\"o'clock\", 'oclock'),\n",
       " ('knocked', 'nock'),\n",
       " ('at', 'a'),\n",
       " (\"o'clock\", 'oclock'),\n",
       " ('killed', 'kild'),\n",
       " ('saw', 'see'),\n",
       " ('been', 'bean'),\n",
       " ('knocked', 'nock'),\n",
       " ('called', 'cald'),\n",
       " ('came', 'cam'),\n",
       " ('killed', 'killd'),\n",
       " ('there', 'the'),\n",
       " ('Her', 'Here'),\n",
       " ('eyes', 'iyes'),\n",
       " ('have to', 'haveto'),\n",
       " ('before', 'be for'),\n",
       " ('anything', 'any thing'),\n",
       " ('else', 'als'),\n",
       " ('wheel', 'weel'),\n",
       " ('wheel', 'weel'),\n",
       " ('sallies', 'sally'),\n",
       " ('others', 'other'),\n",
       " ('rounds', 'rouns'),\n",
       " ('do', 'don'),\n",
       " ('ring', 'rings'),\n",
       " ('be', 'we'),\n",
       " ('breaks', 'brakes'),\n",
       " ('careful', 'carfull'),\n",
       " (\"Cynthia's\", 'Cynthia')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_50_error_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5daf8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'bell ringing',\n",
       " 'wakh',\n",
       " 'sexeon',\n",
       " 'cow boys',\n",
       " 'colbe',\n",
       " 'tv',\n",
       " 'iyes',\n",
       " 'oclock',\n",
       " 'nock',\n",
       " 'kild',\n",
       " 'see',\n",
       " 'cald',\n",
       " 'killd',\n",
       " 'the',\n",
       " 'haveto',\n",
       " 'be for',\n",
       " 'als',\n",
       " 'sally',\n",
       " 'other',\n",
       " 'rouns',\n",
       " 'brakes',\n",
       " 'carfull',\n",
       " 'cynthia']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_that_not_include # List of words not found in their alternative words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e2bc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ago', 'ao', 'bo', 'do', 'ego', 'fo', 'g', 'g', 'ga', 'ga', 'ge', 'ge', 'geo', 'gi', 'gio', 'goa', 'gob', 'god', 'god', 'gog', 'goi', 'gol', 'gon', 'goo', 'gor', 'gor', 'gos', 'got', 'goy', 'ho', 'ho', 'io', 'io', 'jo', 'jo', 'ko', 'ko', 'lo', 'lo', 'mo', 'mo', 'no', 'no', 'o', 'o', 'po', 'po', 'ro', 'so', 'to', 'wo', 'yo', 'zo', 'do', 'no', 'so', 'to']\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "['rakh', 'wah', 'waka', 'wake', 'wakf', 'wakhi', 'waky', 'wash', 'wath', 'wash']\n",
      "\n",
      "\n",
      "['sexern', 'sexton']\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "['cole', 'cole']\n",
      "\n",
      "\n",
      "['t', 't', 'ta', 'tav', 'td', 'te', 'th', 'ti', 'ti', 'to', 'tu', 'v', 'v', 'to']\n",
      "\n",
      "\n",
      "['ides', 'yes', 'yes']\n",
      "\n",
      "\n",
      "['clock', 'ollock', 'clock']\n",
      "\n",
      "\n",
      "['bock', 'cock', 'dock', 'hock', 'jock', 'jock', 'knock', 'lock', 'mock', 'neck', 'nick', 'nick', 'nook', 'ock', 'pock', 'rock', 'snock', 'sock', 'tock', 'yock', 'lock', 'neck', 'sock']\n",
      "\n",
      "\n",
      "['gild', 'keld', 'kil', 'kill', 'kiln', 'kilo', 'kilp', 'kilt', 'kind', 'mild', 'wild', 'kind']\n",
      "\n",
      "\n",
      "['bee', 'bee', 'cee', 'dee', 'fee', 'gee', 'gee', 'kee', 'lee', 'lee', 'nee', 'pee', 'ree', 'ree', 'se', 'sea', 'sec', 'seed', 'seek', 'seel', 'seem', 'seen', 'seep', 'seer', 'seg', 'sele', 'seme', 'sen', 'ser', 'sere', 'sere', 'set', 'sew', 'sex', 'sey', 'she', 'shee', 'sie', 'skee', 'slee', 'smee', 'snee', 'soe', 'sue', 'sue', 'sye', 'tee', 'usee', 'vee', 'wee', 'yee', 'zee', 'bee', 'sea', 'seed', 'seem', 'sex']\n",
      "\n",
      "\n",
      "['bald', 'cad', 'caid', 'cal', 'calf', 'calid', 'calk', 'call', 'calm', 'calp', 'calx', 'cand', 'card', 'cauld', 'cold', 'scald', 'tald', 'card', 'cold']\n",
      "\n",
      "\n",
      "['kill', 'killy']\n",
      "\n",
      "\n",
      "['che', 'he', 'rhe', 'she', 'tae', 'tche', 'te', 'tee', 'th', 'tha', 'thea', 'theb', 'thee', 'them', 'then', 'theo', 'thew', 'they', 'tho', 'tho', 'thy', 'tie', 'toe', 'tue', 'tye', 'he', 'then', 'toe']\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "['aes', 'al', 'al', 'ala', 'alas', 'alb', 'alb', 'ale', 'alf', 'alf', 'alk', 'all', 'alms', 'aln', 'alo', 'alp', 'also', 'alt', 'aly', 'as', 'as', 'ass', 'aus', 'els', 'hals', 'all', 'as']\n",
      "\n",
      "\n",
      "['ally', 'ally', 'bally', 'dally', 'fally', 'gally', 'pally', 'rally', 'sably', 'sadly', 'saily', 'salay', 'salle', 'saltly', 'salty', 'salvy', 'selly', 'silly', 'smally', 'soally', 'sully', 'tally', 'wally']\n",
      "\n",
      "\n",
      "['bother', 'ether', 'fother', 'ither', 'mother', 'nother', 'ocher', 'otter', 'outher', 'pother', 'rother', 'tother', 'mother']\n",
      "\n",
      "\n",
      "['roun', 'round', 'round']\n",
      "\n",
      "\n",
      "['braces', 'brake', 'braker', 'brake']\n",
      "\n",
      "\n",
      "['carful']\n",
      "\n",
      "\n",
      "['cynthian']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in list_that_not_include:\n",
    "    print(alternative_words[word])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ef7bb",
   "metadata": {},
   "source": [
    "\n",
    "<div dir='rtl'>\n",
    "<u> סיבות: </u>\n",
    " </div>  \n",
    " <br>\n",
    " <div dir='rtl'>\n",
    "    \n",
    "- הפונקציה נותנת לנו את המילים עם טעות 1 , אך מתוך 50 המילים הראשונות המילה הנכונה מגיעה אחרי יותר משינוי אחד ולכן לא מופיעה ברשימה \n",
    "- סיומות של מילה שהאלגוריתם מזהה אותם בצורה לא תקינה - לדוגמה 'rounds', 'rouns' הפונקציה החזירה round אך הוא החשיב את ה-s כחלק מהמילה ולא כרבים\n",
    "\n",
    "      \n",
    "</div>\n",
    "\n",
    "  <div dir='rtl'>\n",
    "<u>הצעות לשיפור:</u>\n",
    "</div>\n",
    "<br>\n",
    "<div dir='rtl'>\n",
    "    \n",
    "- להחזיר בפונקציה מילים עם כל טעות אפשרית ואז נמצא את המילה הנכונה ברשימה\n",
    "- להוריד מהמילה שבודקים סיומות של ed,ing וכו' \n",
    "-לבדוק לפי שורש המילה\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be577a",
   "metadata": {},
   "source": [
    "<h1 style='color:red'>Q3 - Similarity between texts:</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17109074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train documents:\n",
    "news_group = fetch_20newsgroups(subset='train')\n",
    "\n",
    "#news_group.filenames\n",
    "news_group_data = news_group.data\n",
    "news_group_target_names = news_group.target_names\n",
    "news_group_target = news_group.target\n",
    "\n",
    "# test documents:\n",
    "news_group_test = fetch_20newsgroups(subset='test')\n",
    "#news_group_test.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d3d7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                token_pattern='\\\\b[a-zA-Z]{2,}\\\\b')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data into vectors (without including stop words and undefined words)\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords,token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
    "vectorizer.fit(news_group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c064b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = list(vectorizer.vocabulary_.keys()) # list of our words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e1d306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lerxst',\n",
       " 'wam',\n",
       " 'umd',\n",
       " 'edu',\n",
       " 'thing',\n",
       " 'subject',\n",
       " 'car',\n",
       " 'nntp',\n",
       " 'posting',\n",
       " 'host',\n",
       " 'organization',\n",
       " 'university',\n",
       " 'maryland',\n",
       " 'college',\n",
       " 'park',\n",
       " 'lines',\n",
       " 'wondering',\n",
       " 'anyone',\n",
       " 'could',\n",
       " 'enlighten',\n",
       " 'saw',\n",
       " 'day',\n",
       " 'door',\n",
       " 'sports',\n",
       " 'looked',\n",
       " 'late',\n",
       " 'early',\n",
       " 'called',\n",
       " 'bricklin',\n",
       " 'doors',\n",
       " 'really',\n",
       " 'small',\n",
       " 'addition',\n",
       " 'front',\n",
       " 'bumper',\n",
       " 'separate',\n",
       " 'rest',\n",
       " 'body',\n",
       " 'know',\n",
       " 'tellme',\n",
       " 'model',\n",
       " 'name',\n",
       " 'engine',\n",
       " 'specs',\n",
       " 'years',\n",
       " 'production',\n",
       " 'made',\n",
       " 'history',\n",
       " 'whatever',\n",
       " 'info',\n",
       " 'funky',\n",
       " 'looking',\n",
       " 'please',\n",
       " 'mail',\n",
       " 'thanks',\n",
       " 'il',\n",
       " 'brought',\n",
       " 'neighborhood',\n",
       " 'guykuo',\n",
       " 'carson',\n",
       " 'washington',\n",
       " 'guy',\n",
       " 'kuo',\n",
       " 'si',\n",
       " 'clock',\n",
       " 'poll',\n",
       " 'final',\n",
       " 'call',\n",
       " 'summary',\n",
       " 'reports',\n",
       " 'keywords',\n",
       " 'acceleration',\n",
       " 'upgrade',\n",
       " 'article',\n",
       " 'shelley',\n",
       " 'fair',\n",
       " 'number',\n",
       " 'brave',\n",
       " 'souls',\n",
       " 'upgraded',\n",
       " 'oscillator',\n",
       " 'shared',\n",
       " 'experiences',\n",
       " 'send',\n",
       " 'brief',\n",
       " 'message',\n",
       " 'detailing',\n",
       " 'procedure',\n",
       " 'top',\n",
       " 'speed',\n",
       " 'attained',\n",
       " 'cpu',\n",
       " 'rated',\n",
       " 'add',\n",
       " 'cards',\n",
       " 'adapters',\n",
       " 'heat',\n",
       " 'sinks',\n",
       " 'hour',\n",
       " 'usage',\n",
       " 'per',\n",
       " 'floppy',\n",
       " 'disk',\n",
       " 'functionality',\n",
       " 'floppies',\n",
       " 'especially',\n",
       " 'requested',\n",
       " 'summarizing',\n",
       " 'next',\n",
       " 'two',\n",
       " 'days',\n",
       " 'network',\n",
       " 'knowledge',\n",
       " 'base',\n",
       " 'done',\n",
       " 'answered',\n",
       " 'twillis',\n",
       " 'ec',\n",
       " 'ecn',\n",
       " 'purdue',\n",
       " 'thomas',\n",
       " 'willis',\n",
       " 'pb',\n",
       " 'questions',\n",
       " 'engineering',\n",
       " 'computer',\n",
       " 'distribution',\n",
       " 'usa',\n",
       " 'well',\n",
       " 'folks',\n",
       " 'mac',\n",
       " 'plus',\n",
       " 'finally',\n",
       " 'gave',\n",
       " 'ghost',\n",
       " 'weekend',\n",
       " 'starting',\n",
       " 'life',\n",
       " 'way',\n",
       " 'back',\n",
       " 'sooo',\n",
       " 'market',\n",
       " 'new',\n",
       " 'machine',\n",
       " 'bit',\n",
       " 'sooner',\n",
       " 'intended',\n",
       " 'picking',\n",
       " 'powerbook',\n",
       " 'maybe',\n",
       " 'bunch',\n",
       " 'hopefully',\n",
       " 'somebody',\n",
       " 'answer',\n",
       " 'anybody',\n",
       " 'dirt',\n",
       " 'round',\n",
       " 'introductions',\n",
       " 'expected',\n",
       " 'heard',\n",
       " 'supposed',\n",
       " 'make',\n",
       " 'appearence',\n",
       " 'summer',\n",
       " 'anymore',\n",
       " 'since',\n",
       " 'access',\n",
       " 'macleak',\n",
       " 'rumors',\n",
       " 'price',\n",
       " 'drops',\n",
       " 'line',\n",
       " 'like',\n",
       " 'ones',\n",
       " 'duo',\n",
       " 'went',\n",
       " 'recently',\n",
       " 'impression',\n",
       " 'display',\n",
       " 'probably',\n",
       " 'swing',\n",
       " 'got',\n",
       " 'rather',\n",
       " 'feel',\n",
       " 'much',\n",
       " 'better',\n",
       " 'yea',\n",
       " 'looks',\n",
       " 'great',\n",
       " 'store',\n",
       " 'wow',\n",
       " 'good',\n",
       " 'solicit',\n",
       " 'opinions',\n",
       " 'people',\n",
       " 'use',\n",
       " 'worth',\n",
       " 'taking',\n",
       " 'size',\n",
       " 'money',\n",
       " 'hit',\n",
       " 'get',\n",
       " 'active',\n",
       " 'realize',\n",
       " 'real',\n",
       " 'subjective',\n",
       " 'question',\n",
       " 'played',\n",
       " 'around',\n",
       " 'machines',\n",
       " 'breifly',\n",
       " 'figured',\n",
       " 'actually',\n",
       " 'uses',\n",
       " 'daily',\n",
       " 'might',\n",
       " 'prove',\n",
       " 'helpful',\n",
       " 'hellcats',\n",
       " 'perform',\n",
       " 'advance',\n",
       " 'email',\n",
       " 'post',\n",
       " 'news',\n",
       " 'reading',\n",
       " 'time',\n",
       " 'premium',\n",
       " 'finals',\n",
       " 'corner',\n",
       " 'tom',\n",
       " 'electrical',\n",
       " 'convictions',\n",
       " 'dangerous',\n",
       " 'enemies',\n",
       " 'truth',\n",
       " 'lies',\n",
       " 'nietzsche',\n",
       " 'jgreen',\n",
       " 'amber',\n",
       " 'joe',\n",
       " 'green',\n",
       " 'weitek',\n",
       " 'harris',\n",
       " 'systems',\n",
       " 'division',\n",
       " 'world',\n",
       " 'ssd',\n",
       " 'csd',\n",
       " 'com',\n",
       " 'newsreader',\n",
       " 'tin',\n",
       " 'version',\n",
       " 'robert',\n",
       " 'kyanko',\n",
       " 'rob',\n",
       " 'rjck',\n",
       " 'uucp',\n",
       " 'wrote',\n",
       " 'abraxis',\n",
       " 'iastate',\n",
       " 'writes',\n",
       " 'graphics',\n",
       " 'chip',\n",
       " 'far',\n",
       " 'low',\n",
       " 'level',\n",
       " 'stuff',\n",
       " 'goes',\n",
       " 'pretty',\n",
       " 'nice',\n",
       " 'quadrilateral',\n",
       " 'fill',\n",
       " 'command',\n",
       " 'requires',\n",
       " 'four',\n",
       " 'points',\n",
       " 'address',\n",
       " 'phone',\n",
       " 'information',\n",
       " 'corporation',\n",
       " 'scares',\n",
       " 'person',\n",
       " 'sense',\n",
       " 'humor',\n",
       " 'jonathan',\n",
       " 'winters',\n",
       " 'jcm',\n",
       " 'head',\n",
       " 'cfa',\n",
       " 'harvard',\n",
       " 'mcdowell',\n",
       " 'shuttle',\n",
       " 'launch',\n",
       " 'smithsonian',\n",
       " 'astrophysical',\n",
       " 'observatory',\n",
       " 'cambridge',\n",
       " 'sci',\n",
       " 'std',\n",
       " 'tombaker',\n",
       " 'baker',\n",
       " 'cs',\n",
       " 'cmu',\n",
       " 'etrat',\n",
       " 'ttu',\n",
       " 'pack',\n",
       " 'rat',\n",
       " 'clear',\n",
       " 'caution',\n",
       " 'warning',\n",
       " 'memory',\n",
       " 'verify',\n",
       " 'unexpected',\n",
       " 'errors',\n",
       " 'error',\n",
       " 'sorry',\n",
       " 'dumb',\n",
       " 'parity',\n",
       " 'previously',\n",
       " 'known',\n",
       " 'conditions',\n",
       " 'waivered',\n",
       " 'yes',\n",
       " 'already',\n",
       " 'knew',\n",
       " 'curious',\n",
       " 'meaning',\n",
       " 'quote',\n",
       " 'understanding',\n",
       " 'basically',\n",
       " 'bugs',\n",
       " 'system',\n",
       " 'software',\n",
       " 'things',\n",
       " 'checked',\n",
       " 'right',\n",
       " 'values',\n",
       " 'yet',\n",
       " 'set',\n",
       " 'till',\n",
       " 'suchlike',\n",
       " 'fix',\n",
       " 'code',\n",
       " 'possibly',\n",
       " 'introduce',\n",
       " 'tell',\n",
       " 'crew',\n",
       " 'ok',\n",
       " 'see',\n",
       " 'liftoff',\n",
       " 'ignore',\n",
       " 'dfo',\n",
       " 'vttoulu',\n",
       " 'tko',\n",
       " 'vtt',\n",
       " 'fi',\n",
       " 'foxvog',\n",
       " 'douglas',\n",
       " 'rewording',\n",
       " 'second',\n",
       " 'amendment',\n",
       " 'ideas',\n",
       " 'transfer',\n",
       " 'stratus',\n",
       " 'cdt',\n",
       " 'sw',\n",
       " 'tavares',\n",
       " 'ousrvr',\n",
       " 'oulu',\n",
       " 'ulowell',\n",
       " 'jrutledg',\n",
       " 'john',\n",
       " 'lawrence',\n",
       " 'rutledge',\n",
       " 'massive',\n",
       " 'destructive',\n",
       " 'power',\n",
       " 'many',\n",
       " 'modern',\n",
       " 'weapons',\n",
       " 'makes',\n",
       " 'cost',\n",
       " 'accidental',\n",
       " 'crimial',\n",
       " 'mass',\n",
       " 'destruction',\n",
       " 'need',\n",
       " 'control',\n",
       " 'government',\n",
       " 'individual',\n",
       " 'would',\n",
       " 'result',\n",
       " 'needless',\n",
       " 'deaths',\n",
       " 'millions',\n",
       " 'keep',\n",
       " 'bear',\n",
       " 'non',\n",
       " 'existant',\n",
       " 'stating',\n",
       " 'coming',\n",
       " 'say',\n",
       " 'disagree',\n",
       " 'every',\n",
       " 'count',\n",
       " 'believe',\n",
       " 'individuals',\n",
       " 'find',\n",
       " 'hard',\n",
       " 'support',\n",
       " 'neighbor',\n",
       " 'nuclear',\n",
       " 'biological',\n",
       " 'nerve',\n",
       " 'gas',\n",
       " 'property',\n",
       " 'cannot',\n",
       " 'even',\n",
       " 'agree',\n",
       " 'keeping',\n",
       " 'hands',\n",
       " 'hope',\n",
       " 'us',\n",
       " 'sign',\n",
       " 'blank',\n",
       " 'checks',\n",
       " 'course',\n",
       " 'term',\n",
       " 'must',\n",
       " 'rigidly',\n",
       " 'defined',\n",
       " 'bill',\n",
       " 'doug',\n",
       " 'says',\n",
       " 'means',\n",
       " 'cbw',\n",
       " 'nukes',\n",
       " 'sarah',\n",
       " 'brady',\n",
       " 'street',\n",
       " 'sweeper',\n",
       " 'shotguns',\n",
       " 'semi',\n",
       " 'automatic',\n",
       " 'sks',\n",
       " 'rifles',\n",
       " 'doubt',\n",
       " 'using',\n",
       " 'allegedly',\n",
       " 'immediately',\n",
       " 'follows',\n",
       " 'thousands',\n",
       " 'killed',\n",
       " 'year',\n",
       " 'handguns',\n",
       " 'easily',\n",
       " 'reduced',\n",
       " 'putting',\n",
       " 'reasonable',\n",
       " 'restrictions',\n",
       " 'mean',\n",
       " 'read',\n",
       " 'presenting',\n",
       " 'first',\n",
       " 'argument',\n",
       " 'commonly',\n",
       " 'understood',\n",
       " 'switching',\n",
       " 'topics',\n",
       " 'point',\n",
       " 'evidently',\n",
       " 'show',\n",
       " 'allowed',\n",
       " 'later',\n",
       " 'analysis',\n",
       " 'given',\n",
       " 'consider',\n",
       " 'another',\n",
       " 'class',\n",
       " 'rocket',\n",
       " 'speak',\n",
       " 'company',\n",
       " 'vos',\n",
       " 'write',\n",
       " 'today',\n",
       " 'special',\n",
       " 'investors',\n",
       " 'packet',\n",
       " 'bmdelane',\n",
       " 'quads',\n",
       " 'uchicago',\n",
       " 'brian',\n",
       " 'manning',\n",
       " 'delaney',\n",
       " 'brain',\n",
       " 'tumor',\n",
       " 'treatment',\n",
       " 'reply',\n",
       " 'midway',\n",
       " 'chicago',\n",
       " 'responded',\n",
       " 'request',\n",
       " 'astrocytomas',\n",
       " 'thank',\n",
       " 'directly',\n",
       " 'bouncing',\n",
       " 'probs',\n",
       " 'sean',\n",
       " 'debra',\n",
       " 'sharon',\n",
       " 'thought',\n",
       " 'publicly',\n",
       " 'everyone',\n",
       " 'sure',\n",
       " 'glad',\n",
       " 'accidentally',\n",
       " 'rn',\n",
       " 'instead',\n",
       " 'rm',\n",
       " 'trying',\n",
       " 'delete',\n",
       " 'file',\n",
       " 'last',\n",
       " 'september',\n",
       " 'hmmm',\n",
       " 'bgrubb',\n",
       " 'dante',\n",
       " 'nmsu',\n",
       " 'grubb',\n",
       " 'ide',\n",
       " 'vs',\n",
       " 'scsi',\n",
       " 'mexico',\n",
       " 'state',\n",
       " 'las',\n",
       " 'cruces',\n",
       " 'nm',\n",
       " 'psuvm',\n",
       " 'psu',\n",
       " 'pc',\n",
       " 'magazine',\n",
       " 'april',\n",
       " 'although',\n",
       " 'twice',\n",
       " 'fasst',\n",
       " 'esdi',\n",
       " 'faster',\n",
       " 'devices',\n",
       " 'acceptance',\n",
       " 'long',\n",
       " 'stalled',\n",
       " 'incompatability',\n",
       " 'problems',\n",
       " 'installation',\n",
       " 'headaches',\n",
       " 'love',\n",
       " 'writers',\n",
       " 'stupid',\n",
       " 'statements',\n",
       " 'performance',\n",
       " 'numbers',\n",
       " 'list',\n",
       " 'actual',\n",
       " 'ranges',\n",
       " 'convince',\n",
       " 'statement',\n",
       " 'absurd',\n",
       " 'ii',\n",
       " 'always',\n",
       " 'standard',\n",
       " 'versions',\n",
       " 'shows',\n",
       " 'controler',\n",
       " 'range',\n",
       " 'indeed',\n",
       " 'controller',\n",
       " 'burst',\n",
       " 'note',\n",
       " 'increase',\n",
       " 'quadra',\n",
       " 'exist',\n",
       " 'mode',\n",
       " 'wide',\n",
       " 'fast',\n",
       " 'data',\n",
       " 'correct',\n",
       " 'reach',\n",
       " 'facts',\n",
       " 'posted',\n",
       " 'newsgroup',\n",
       " 'ibm',\n",
       " 'sheet',\n",
       " 'available',\n",
       " 'ftp',\n",
       " 'sumex',\n",
       " 'aim',\n",
       " 'stanford',\n",
       " 'report',\n",
       " 'compare',\n",
       " 'txt',\n",
       " 'may',\n",
       " 'still',\n",
       " 'part',\n",
       " 'problem',\n",
       " 'inconsiant',\n",
       " 'though',\n",
       " 'documented',\n",
       " 'apple',\n",
       " 'salesperson',\n",
       " 'said',\n",
       " 'maximum',\n",
       " 'synchronous',\n",
       " 'ansynchronous',\n",
       " 'slower',\n",
       " 'seems',\n",
       " 'interface',\n",
       " 'think',\n",
       " 'driven',\n",
       " 'true',\n",
       " 'go',\n",
       " 'slam',\n",
       " 'understand',\n",
       " 'going',\n",
       " 'one',\n",
       " 'reference',\n",
       " 'digital',\n",
       " 'review',\n",
       " 'oct',\n",
       " 'iscsvax',\n",
       " 'uni',\n",
       " 'win',\n",
       " 'icon',\n",
       " 'help',\n",
       " 'northern',\n",
       " 'iowa',\n",
       " 'downloaded',\n",
       " 'several',\n",
       " 'icons',\n",
       " 'bmp',\n",
       " 'figure',\n",
       " 'change',\n",
       " 'wallpaper',\n",
       " 'appreciated',\n",
       " 'thanx',\n",
       " 'brando',\n",
       " 'ps',\n",
       " 'kerr',\n",
       " 'cso',\n",
       " 'uiuc',\n",
       " 'stan',\n",
       " 'sigma',\n",
       " 'designs',\n",
       " 'double',\n",
       " 'illinois',\n",
       " 'urbana',\n",
       " 'po',\n",
       " 'cwru',\n",
       " 'joseph',\n",
       " 'pellettiere',\n",
       " 'board',\n",
       " 'hardware',\n",
       " 'compression',\n",
       " 'works',\n",
       " 'autodoubler',\n",
       " 'also',\n",
       " 'work',\n",
       " 'diskdoubler',\n",
       " 'due',\n",
       " 'licensing',\n",
       " 'stac',\n",
       " 'technologies',\n",
       " 'owners',\n",
       " 'technology',\n",
       " 'writing',\n",
       " 'lost',\n",
       " 'wrong',\n",
       " 'whether',\n",
       " 'fault',\n",
       " 'something',\n",
       " 'else',\n",
       " 'however',\n",
       " 'decompress',\n",
       " 'troubled',\n",
       " 'recompress',\n",
       " 'without',\n",
       " 'usually',\n",
       " 'reappears',\n",
       " 'mentioned',\n",
       " 'freeware',\n",
       " 'expansion',\n",
       " 'utility',\n",
       " 'dd',\n",
       " 'expand',\n",
       " 'compressed',\n",
       " 'unless',\n",
       " 'installed',\n",
       " 'product',\n",
       " 'unlikely',\n",
       " 'holes',\n",
       " 'related',\n",
       " 'fixed',\n",
       " 'sad',\n",
       " 'reluctant',\n",
       " 'buy',\n",
       " 'stinky',\n",
       " 'hey',\n",
       " 'competition',\n",
       " 'computing',\n",
       " 'communications',\n",
       " 'services',\n",
       " 'office',\n",
       " 'stankerr',\n",
       " 'irwin',\n",
       " 'cmptrc',\n",
       " 'lonestar',\n",
       " 'org',\n",
       " 'arnstein',\n",
       " 'recommendation',\n",
       " 'duc',\n",
       " 'expires',\n",
       " 'sat',\n",
       " 'gmt',\n",
       " 'computrac',\n",
       " 'inc',\n",
       " 'richardson',\n",
       " 'tx',\n",
       " 'ducati',\n",
       " 'gts',\n",
       " 'runs',\n",
       " 'paint',\n",
       " 'bronze',\n",
       " 'brown',\n",
       " 'orange',\n",
       " 'faded',\n",
       " 'leaks',\n",
       " 'oil',\n",
       " 'pops',\n",
       " 'accel',\n",
       " 'shop',\n",
       " 'trans',\n",
       " 'leak',\n",
       " 'sold',\n",
       " 'bike',\n",
       " 'owner',\n",
       " 'want',\n",
       " 'thinking',\n",
       " 'stable',\n",
       " 'mate',\n",
       " 'beemer',\n",
       " 'jap',\n",
       " 'axis',\n",
       " 'motors',\n",
       " 'tuba',\n",
       " 'honk',\n",
       " 'therefore',\n",
       " 'dod',\n",
       " 'david',\n",
       " 'terminus',\n",
       " 'ericsson',\n",
       " 'se',\n",
       " 'bold',\n",
       " 'popular',\n",
       " 'morality',\n",
       " 'camtec',\n",
       " 'electronics',\n",
       " 'leicester',\n",
       " 'england',\n",
       " 'bangkok',\n",
       " 'freenet',\n",
       " 'carleton',\n",
       " 'ca',\n",
       " 'james',\n",
       " 'owens',\n",
       " 'previous',\n",
       " 'rude',\n",
       " 'hold',\n",
       " 'end',\n",
       " 'different',\n",
       " 'stick',\n",
       " 'look',\n",
       " 'intent',\n",
       " 'explaining',\n",
       " 'jung',\n",
       " 'moral',\n",
       " 'god',\n",
       " 'overlooked',\n",
       " 'main',\n",
       " 'seem',\n",
       " 'saying',\n",
       " 'unknowable',\n",
       " 'yep',\n",
       " 'jew',\n",
       " 'jewish',\n",
       " 'jews',\n",
       " 'covenant',\n",
       " 'yhwh',\n",
       " 'patriarchs',\n",
       " 'abraham',\n",
       " 'moses',\n",
       " 'case',\n",
       " 'establishes',\n",
       " 'follow',\n",
       " 'mankind',\n",
       " 'decide',\n",
       " 'boundaries',\n",
       " 'fall',\n",
       " 'sadducees',\n",
       " 'believed',\n",
       " 'torah',\n",
       " 'required',\n",
       " 'whereas',\n",
       " 'pharisees',\n",
       " 'ancestors',\n",
       " 'judaism',\n",
       " 'interpretation',\n",
       " 'lead',\n",
       " 'nuances',\n",
       " 'talmud',\n",
       " 'essence',\n",
       " 'biblical',\n",
       " 'man',\n",
       " 'christian',\n",
       " 'necessarily',\n",
       " 'indicate',\n",
       " 'anything',\n",
       " 'outside',\n",
       " 'relationship',\n",
       " 'speculate',\n",
       " 'comes',\n",
       " 'mind',\n",
       " 'created',\n",
       " 'image',\n",
       " 'committed',\n",
       " 'live',\n",
       " 'christ',\n",
       " 'example',\n",
       " 'pressed',\n",
       " 'argue',\n",
       " 'kind',\n",
       " 'trouble',\n",
       " 'come',\n",
       " 'conclusion',\n",
       " 'upsets',\n",
       " 'cart',\n",
       " 'wants',\n",
       " 'script',\n",
       " 'shaky',\n",
       " 'foundation',\n",
       " 'mix',\n",
       " 'metaphors',\n",
       " 'unashamedly',\n",
       " 'living',\n",
       " 'little',\n",
       " 'jesus',\n",
       " 'recorded',\n",
       " 'utterances',\n",
       " 'narratives',\n",
       " 'followers',\n",
       " 'references',\n",
       " 'comtemporary',\n",
       " 'historians',\n",
       " 'revelation',\n",
       " 'aside',\n",
       " 'hand',\n",
       " 'worse',\n",
       " 'attempt',\n",
       " 'debunk',\n",
       " 'christianity',\n",
       " 'initially',\n",
       " 'bible',\n",
       " 'interpret',\n",
       " 'humanity',\n",
       " 'guess',\n",
       " 'faith',\n",
       " 'relevation',\n",
       " 'inherent',\n",
       " 'subjectiveness',\n",
       " 'metaphysically',\n",
       " 'multiple',\n",
       " 'codes',\n",
       " 'absolute',\n",
       " 'theologically',\n",
       " 'questionable',\n",
       " 'undoubtably',\n",
       " 'founded',\n",
       " 'parent',\n",
       " 'child',\n",
       " 'never',\n",
       " 'swear',\n",
       " 'assume',\n",
       " 'swears',\n",
       " 'simply',\n",
       " 'told',\n",
       " 'trooper',\n",
       " 'pub',\n",
       " 'bar',\n",
       " 'children',\n",
       " 'wrongness',\n",
       " 'disobeys',\n",
       " 'inappropriate',\n",
       " 'quite',\n",
       " 'happy',\n",
       " 'animals',\n",
       " 'analogy',\n",
       " 'water',\n",
       " 'knows',\n",
       " 'type',\n",
       " 'gist',\n",
       " 'incidentally',\n",
       " 'young',\n",
       " 'considers',\n",
       " 'directive',\n",
       " 'gets',\n",
       " 'older',\n",
       " 'piaget',\n",
       " 'learns',\n",
       " 'religion',\n",
       " 'oh',\n",
       " 'sea',\n",
       " 'fishes',\n",
       " 'cried',\n",
       " 'swam',\n",
       " 'clearness',\n",
       " 'rodc',\n",
       " 'fc',\n",
       " 'hp',\n",
       " 'rod',\n",
       " 'cerkoney',\n",
       " 'hpfcmrc',\n",
       " 'hewlett',\n",
       " 'packard',\n",
       " 'fort',\n",
       " 'collins',\n",
       " 'co',\n",
       " 'regards',\n",
       " 'ms',\n",
       " 'east',\n",
       " 'harmony',\n",
       " 'rd',\n",
       " 'hpdesk',\n",
       " 'ux',\n",
       " 'lerc',\n",
       " 'nasa',\n",
       " 'gov',\n",
       " 'mckissock',\n",
       " 'space',\n",
       " 'station',\n",
       " 'redesign',\n",
       " 'jsc',\n",
       " 'alternative',\n",
       " 'lewis',\n",
       " 'research',\n",
       " 'center',\n",
       " 'cleveland',\n",
       " 'ohio',\n",
       " 'vax',\n",
       " 'vms',\n",
       " 'vnews',\n",
       " 'aio',\n",
       " 'kjenks',\n",
       " 'gothamcity',\n",
       " 'description',\n",
       " 'external',\n",
       " 'tank',\n",
       " 'option',\n",
       " 'ssf',\n",
       " 'deleted',\n",
       " 'mark',\n",
       " 'proposed',\n",
       " 'design',\n",
       " 'shea',\n",
       " 'committee',\n",
       " 'crystal',\n",
       " 'city',\n",
       " 'warmly',\n",
       " 'received',\n",
       " 'hear',\n",
       " 'based',\n",
       " 'wingless',\n",
       " 'orbiter',\n",
       " 'likely',\n",
       " 'yo',\n",
       " 'ken',\n",
       " 'let',\n",
       " 'options',\n",
       " 'edition',\n",
       " 'york',\n",
       " 'times',\n",
       " 'connor',\n",
       " 'panel',\n",
       " 'proposals',\n",
       " 'dropped',\n",
       " 'giant',\n",
       " 'fuel',\n",
       " 'tanks',\n",
       " 'used',\n",
       " 'launching',\n",
       " 'shuttles',\n",
       " 'building',\n",
       " 'existing',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bff53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81604\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.vocabulary_)) # number of total words from all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ccd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gets a vector of text and its length, and returns the TF vector\n",
    "def computeTF(CountVector, bagOfWordsCount):\n",
    "    for i in range(len(CountVector)):\n",
    "        CountVector[i] = CountVector[i] / float(bagOfWordsCount)\n",
    "    return CountVector\n",
    "\n",
    "# this function returns the amount of words in the text\n",
    "def number_of_words(text):\n",
    "    list_words=[]\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.isalpha() and word.lower() not in stopwords:\n",
    "            list_words.append(word)\n",
    "    return len(list_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2ccfc",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each text in the train data computes the TF value, using the computeTF function\n",
    "vector_train_texts = [] # contains all the train texts as TF vectors\n",
    "for text in news_groccup_data:\n",
    "    train_cv = vectorizer.transform([text])\n",
    "    train_arr = list(np.array(train_cv.toarray(), dtype = 'float32')) # for space efficiency\n",
    "    TF_train = computcceTF(train_arr[0],number_of_words(text))\n",
    "    vector_train_texts.append(TF_train)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c35eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each text in the  test data computes the TF value, using the computeTF function\n",
    "vector_test_texts = [] # contains all the test texts as TF vectors\n",
    "for text in news_group_test.data:\n",
    "    test_cv = vectorizer.transform([text])\n",
    "    test_arr = list(np.array(test_cv.toarray(), dtype = 'float32')) # for space efficiency\n",
    "    TF_test = computeTF(test_arr[0],number_of_words(text))\n",
    "    vector_test_texts.append(TF_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294361a6",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f0b45a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16755994, 0.11645254, 0.06447455, ..., 0.11481771, 0.16457605,\n",
       "        0.08694906],\n",
       "       [0.10223866, 0.10619193, 0.05810201, ..., 0.10144055, 0.14540166,\n",
       "        0.04155199],\n",
       "       [0.17719492, 0.13031621, 0.05656578, ..., 0.07195257, 0.10920127,\n",
       "        0.05944164],\n",
       "       ...,\n",
       "       [0.03066598, 0.02435721, 0.03775938, ..., 0.03955456, 0.03543516,\n",
       "        0.0925846 ],\n",
       "       [0.09075298, 0.10211729, 0.07449681, ..., 0.09267081, 0.09787577,\n",
       "        0.11987286],\n",
       "       [0.12416854, 0.14793591, 0.0764451 , ..., 0.0960954 , 0.11478341,\n",
       "        0.04686013]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the cosine similarity with TF for each text in the text with each text in the train\n",
    "cosine_similarity(vector_train_texts, vector_test_texts, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9c78ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167560</td>\n",
       "      <td>0.116453</td>\n",
       "      <td>0.064475</td>\n",
       "      <td>0.075293</td>\n",
       "      <td>0.049992</td>\n",
       "      <td>0.087478</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.075745</td>\n",
       "      <td>0.140803</td>\n",
       "      <td>0.080457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092189</td>\n",
       "      <td>0.149225</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>0.092119</td>\n",
       "      <td>0.160704</td>\n",
       "      <td>0.104001</td>\n",
       "      <td>0.152039</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>0.164576</td>\n",
       "      <td>0.086949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102239</td>\n",
       "      <td>0.106192</td>\n",
       "      <td>0.058102</td>\n",
       "      <td>0.051626</td>\n",
       "      <td>0.046928</td>\n",
       "      <td>0.058897</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.137460</td>\n",
       "      <td>0.046994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074557</td>\n",
       "      <td>0.130740</td>\n",
       "      <td>0.089923</td>\n",
       "      <td>0.062889</td>\n",
       "      <td>0.075858</td>\n",
       "      <td>0.082983</td>\n",
       "      <td>0.144223</td>\n",
       "      <td>0.101441</td>\n",
       "      <td>0.145402</td>\n",
       "      <td>0.041552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177195</td>\n",
       "      <td>0.130316</td>\n",
       "      <td>0.056566</td>\n",
       "      <td>0.073853</td>\n",
       "      <td>0.027412</td>\n",
       "      <td>0.100187</td>\n",
       "      <td>0.066337</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>0.123532</td>\n",
       "      <td>0.095237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093324</td>\n",
       "      <td>0.119491</td>\n",
       "      <td>0.054574</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.089199</td>\n",
       "      <td>0.073321</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>0.071953</td>\n",
       "      <td>0.109201</td>\n",
       "      <td>0.059442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.122147</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.073521</td>\n",
       "      <td>0.124152</td>\n",
       "      <td>0.099014</td>\n",
       "      <td>0.073152</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.170276</td>\n",
       "      <td>0.092665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189895</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>0.036169</td>\n",
       "      <td>0.059493</td>\n",
       "      <td>0.084222</td>\n",
       "      <td>0.103683</td>\n",
       "      <td>0.128350</td>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.150214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101739</td>\n",
       "      <td>0.094277</td>\n",
       "      <td>0.093954</td>\n",
       "      <td>0.063605</td>\n",
       "      <td>0.141653</td>\n",
       "      <td>0.090356</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.148187</td>\n",
       "      <td>0.057898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143527</td>\n",
       "      <td>0.120808</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>0.054238</td>\n",
       "      <td>0.078061</td>\n",
       "      <td>0.094721</td>\n",
       "      <td>0.136043</td>\n",
       "      <td>0.131228</td>\n",
       "      <td>0.086212</td>\n",
       "      <td>0.127984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>0.069314</td>\n",
       "      <td>0.047189</td>\n",
       "      <td>0.042673</td>\n",
       "      <td>0.072739</td>\n",
       "      <td>0.056132</td>\n",
       "      <td>0.074156</td>\n",
       "      <td>0.080072</td>\n",
       "      <td>0.040285</td>\n",
       "      <td>0.086536</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087167</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.090060</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>0.087010</td>\n",
       "      <td>0.057474</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.112107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.096181</td>\n",
       "      <td>0.061115</td>\n",
       "      <td>0.094743</td>\n",
       "      <td>0.048104</td>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.038785</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.090521</td>\n",
       "      <td>0.065682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.129436</td>\n",
       "      <td>0.074981</td>\n",
       "      <td>0.092294</td>\n",
       "      <td>0.080122</td>\n",
       "      <td>0.065667</td>\n",
       "      <td>0.132285</td>\n",
       "      <td>0.124059</td>\n",
       "      <td>0.088911</td>\n",
       "      <td>0.058076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>0.030666</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.037759</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.082461</td>\n",
       "      <td>0.045810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072679</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.047814</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.040336</td>\n",
       "      <td>0.028551</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.092585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>0.090753</td>\n",
       "      <td>0.102117</td>\n",
       "      <td>0.074497</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.063179</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>0.111850</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081938</td>\n",
       "      <td>0.113750</td>\n",
       "      <td>0.082542</td>\n",
       "      <td>0.078619</td>\n",
       "      <td>0.049737</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.092459</td>\n",
       "      <td>0.092671</td>\n",
       "      <td>0.097876</td>\n",
       "      <td>0.119873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.147936</td>\n",
       "      <td>0.076445</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>0.051865</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.050204</td>\n",
       "      <td>0.033678</td>\n",
       "      <td>0.166945</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092489</td>\n",
       "      <td>0.167101</td>\n",
       "      <td>0.083894</td>\n",
       "      <td>0.049646</td>\n",
       "      <td>0.087105</td>\n",
       "      <td>0.107897</td>\n",
       "      <td>0.113853</td>\n",
       "      <td>0.096095</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.046860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 7532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.167560  0.116453  0.064475  0.075293  0.049992  0.087478  0.042343   \n",
       "1      0.102239  0.106192  0.058102  0.051626  0.046928  0.058897  0.031798   \n",
       "2      0.177195  0.130316  0.056566  0.073853  0.027412  0.100187  0.066337   \n",
       "3      0.117600  0.122147  0.089109  0.073521  0.124152  0.099014  0.073152   \n",
       "4      0.101739  0.094277  0.093954  0.063605  0.141653  0.090356  0.068559   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11309  0.069314  0.047189  0.042673  0.072739  0.056132  0.074156  0.080072   \n",
       "11310  0.096181  0.061115  0.094743  0.048104  0.017218  0.038785  0.038888   \n",
       "11311  0.030666  0.024357  0.037759  0.045533  0.050321  0.013249  0.061995   \n",
       "11312  0.090753  0.102117  0.074497  0.047281  0.063179  0.078421  0.030578   \n",
       "11313  0.124169  0.147936  0.076445  0.042695  0.051865  0.067954  0.050204   \n",
       "\n",
       "           7         8         9     ...      7522      7523      7524  \\\n",
       "0      0.075745  0.140803  0.080457  ...  0.092189  0.149225  0.054428   \n",
       "1      0.035551  0.137460  0.046994  ...  0.074557  0.130740  0.089923   \n",
       "2      0.089001  0.123532  0.095237  ...  0.093324  0.119491  0.054574   \n",
       "3      0.049072  0.170276  0.092665  ...  0.189895  0.128901  0.122240   \n",
       "4      0.030661  0.148187  0.057898  ...  0.143527  0.120808  0.141003   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11309  0.040285  0.086536  0.025358  ...  0.087167  0.039193  0.090060   \n",
       "11310  0.052174  0.090521  0.065682  ...  0.071642  0.129436  0.074981   \n",
       "11311  0.020794  0.082461  0.045810  ...  0.072679  0.030345  0.047814   \n",
       "11312  0.047862  0.111850  0.038735  ...  0.081938  0.113750  0.082542   \n",
       "11313  0.033678  0.166945  0.095394  ...  0.092489  0.167101  0.083894   \n",
       "\n",
       "           7525      7526      7527      7528      7529      7530      7531  \n",
       "0      0.092119  0.160704  0.104001  0.152039  0.114818  0.164576  0.086949  \n",
       "1      0.062889  0.075858  0.082983  0.144223  0.101441  0.145402  0.041552  \n",
       "2      0.089216  0.089199  0.073321  0.120351  0.071953  0.109201  0.059442  \n",
       "3      0.036169  0.059493  0.084222  0.103683  0.128350  0.133799  0.150214  \n",
       "4      0.054238  0.078061  0.094721  0.136043  0.131228  0.086212  0.127984  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11309  0.039591  0.060780  0.049168  0.087010  0.057474  0.036614  0.112107  \n",
       "11310  0.092294  0.080122  0.065667  0.132285  0.124059  0.088911  0.058076  \n",
       "11311  0.030653  0.040336  0.028551  0.011716  0.039555  0.035435  0.092585  \n",
       "11312  0.078619  0.049737  0.112657  0.092459  0.092671  0.097876  0.119873  \n",
       "11313  0.049646  0.087105  0.107897  0.113853  0.096095  0.114783  0.046860  \n",
       "\n",
       "[11314 rows x 7532 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cosine_similarity(vector_train_texts, vector_test_texts,  dense_output=True))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d84def5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9048\n",
       "1        4114\n",
       "2        3172\n",
       "3       10575\n",
       "4       10278\n",
       "        ...  \n",
       "7527     9818\n",
       "7528     9963\n",
       "7529     2018\n",
       "7530     2965\n",
       "7531     7192\n",
       "Length: 7532, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the closet neighbor for each test using the cosine similarity\n",
    "df_tf_cos_predict = df.idxmax(axis = 0)\n",
    "df_tf_cos_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1e442e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9528\\2875048897.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_df_predict = new_df_predict.append(row_df,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_text</th>\n",
       "      <th>per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4114</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3172</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10575</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10278</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>9818</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>9963</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>2018</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>2965</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>7192</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarity_text               per_group\n",
       "0               9048         sci.electronics\n",
       "1               4114               sci.crypt\n",
       "2               3172             alt.atheism\n",
       "3              10575               sci.crypt\n",
       "4              10278             alt.atheism\n",
       "...              ...                     ...\n",
       "7527            9818               sci.space\n",
       "7528            9963      rec.sport.baseball\n",
       "7529            2018      rec.sport.baseball\n",
       "7530            2965             alt.atheism\n",
       "7531            7192  soc.religion.christian\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the topic using the topic of the closet neighbor according to the cosine similarity\n",
    "new_df_predict = pd.DataFrame(columns=['similarity_text', 'per_group'])\n",
    "\n",
    "for i in range(len(df_tf_cos_predict.values)):\n",
    "    row_df = pd.DataFrame({'similarity_text': [df_tf_cos_predict.values[i]],'per_group': [news_group_target_names[news_group_target[df_tf_cos_predict.values[i]]]]})\n",
    "    new_df_predict = new_df_predict.append(row_df,ignore_index=True)\n",
    "new_df_predict   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f202cf3",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449f57d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naor2\\AppData\\Local\\Temp/ipykernel_8596/1282629690.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dot_df[test_count] = vector_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.004420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.002087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 7532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.005291  0.003378  0.002480  0.000927  0.002165  0.001263  0.002101   \n",
       "1      0.002972  0.002836  0.002058  0.000585  0.001871  0.000783  0.001452   \n",
       "2      0.003106  0.002098  0.001208  0.000505  0.000659  0.000803  0.001827   \n",
       "3      0.003821  0.003647  0.003527  0.000932  0.005532  0.001471  0.003735   \n",
       "4      0.002554  0.002175  0.002874  0.000623  0.004876  0.001037  0.002705   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11309  0.001425  0.000891  0.001068  0.000583  0.001582  0.000697  0.002586   \n",
       "11310  0.002894  0.001689  0.003472  0.000564  0.000710  0.000534  0.001838   \n",
       "11311  0.001122  0.000819  0.001684  0.000650  0.002525  0.000222  0.003565   \n",
       "11312  0.002497  0.002581  0.002497  0.000507  0.002383  0.000987  0.001322   \n",
       "11313  0.004026  0.004407  0.003019  0.000540  0.002306  0.001007  0.002558   \n",
       "\n",
       "           7         8         9     ...      7522      7523      7524  \\\n",
       "0      0.002381  0.004699  0.002087  ...  0.002470  0.005952  0.001032   \n",
       "1      0.001029  0.004224  0.001122  ...  0.001839  0.004801  0.001570   \n",
       "2      0.001553  0.002288  0.001371  ...  0.001388  0.002646  0.000574   \n",
       "3      0.001587  0.005848  0.002474  ...  0.005235  0.005291  0.002386   \n",
       "4      0.000766  0.003932  0.001194  ...  0.003057  0.003831  0.002126   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11309  0.000824  0.001880  0.000428  ...  0.001520  0.001018  0.001112   \n",
       "11310  0.001563  0.002878  0.001623  ...  0.001828  0.004919  0.001355   \n",
       "11311  0.000758  0.003190  0.001377  ...  0.002257  0.001403  0.001051   \n",
       "11312  0.001311  0.003253  0.000876  ...  0.001913  0.003953  0.001364   \n",
       "11313  0.001087  0.005721  0.002541  ...  0.002544  0.006844  0.001634   \n",
       "\n",
       "           7525      7526      7527      7528      7529      7530      7531  \n",
       "0      0.001889  0.004371  0.002055  0.004779  0.002811  0.003843  0.002486  \n",
       "1      0.001187  0.001899  0.001510  0.004173  0.002286  0.003125  0.001094  \n",
       "2      0.001015  0.001346  0.000804  0.002100  0.000978  0.001415  0.000943  \n",
       "3      0.000763  0.001665  0.001713  0.003353  0.003233  0.003215  0.004420  \n",
       "4      0.000884  0.001688  0.001488  0.003400  0.002554  0.001600  0.002910  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11309  0.000528  0.001076  0.000632  0.001780  0.000916  0.000556  0.002087  \n",
       "11310  0.001803  0.002076  0.001237  0.003961  0.002894  0.001978  0.001582  \n",
       "11311  0.000728  0.001271  0.000654  0.000427  0.001122  0.000959  0.003069  \n",
       "11312  0.001404  0.001179  0.001940  0.002532  0.001977  0.001991  0.002987  \n",
       "11313  0.001045  0.002432  0.002190  0.003674  0.002415  0.002752  0.001376  \n",
       "\n",
       "[11314 rows x 7532 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_df = pd.DataFrame()\n",
    "\n",
    "for test_count in range(len(vector_test_texts)):\n",
    "    vector_list= []\n",
    "    for train_count in range(len(vector_train_texts)):\n",
    "        vector_list.append(np.dot(vector_test_texts[test_count],vector_train_texts[train_count]))\n",
    "    dot_df[test_count] = vector_list\n",
    "dot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "409823b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9229\n",
       "1       10544\n",
       "2        3172\n",
       "3        3936\n",
       "4        7996\n",
       "        ...  \n",
       "7527     2051\n",
       "7528    10400\n",
       "7529     4633\n",
       "7530     2965\n",
       "7531     9266\n",
       "Length: 7532, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the closet neighbor for each test using the dot product\n",
    "tf_dot_predict = dot_df.idxmax(axis = 0)\n",
    "tf_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce0d113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9528\\2134272011.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_df_predict = new_df_predict.append(row_df,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_text</th>\n",
       "      <th>per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9229</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10544</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3172</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3936</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7996</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>2051</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>10400</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>4633</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>2965</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>9266</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarity_text           per_group\n",
       "0               9229  talk.religion.misc\n",
       "1              10544             sci.med\n",
       "2               3172         alt.atheism\n",
       "3               3936  talk.religion.misc\n",
       "4               7996       comp.graphics\n",
       "...              ...                 ...\n",
       "7527            2051        misc.forsale\n",
       "7528           10400       comp.graphics\n",
       "7529            4633      comp.windows.x\n",
       "7530            2965         alt.atheism\n",
       "7531            9266     rec.motorcycles\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the topic using the topic of the closet neighbor according to the dot product\n",
    "new_df_predict = pd.DataFrame(columns=['similarity_text', 'per_group'])\n",
    "\n",
    "for i in range(len(tf_dot_predict.values)):\n",
    "    row_df = pd.DataFrame({'similarity_text': [tf_dot_predict.values[i]],'per_group': [news_group_target_names[news_group_target[tf_dot_predict.values[i]]]]})\n",
    "    new_df_predict = new_df_predict.append(row_df,ignore_index=True)\n",
    "new_df_predict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c33670",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7dc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tf-idf\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "TfidfV = TfidfVectorizer(stop_words=stopwords,token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
    "TfidfV .fit(news_group_data)\n",
    "tfidf_train = TfidfV.fit_transform(news_group_data)\n",
    "tfidf_test = TfidfV.transform(news_group_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed9979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08332137, 0.03527536, 0.01853714, ..., 0.08742758, 0.05421031,\n",
       "        0.06243403],\n",
       "       [0.03270318, 0.0265544 , 0.0138742 , ..., 0.04038842, 0.05893349,\n",
       "        0.02222038],\n",
       "       [0.12736379, 0.0644189 , 0.04219289, ..., 0.1020233 , 0.06047534,\n",
       "        0.07989148],\n",
       "       ...,\n",
       "       [0.04359934, 0.01646304, 0.02089325, ..., 0.05089863, 0.02096217,\n",
       "        0.04041883],\n",
       "       [0.04901693, 0.03379068, 0.03787461, ..., 0.05323483, 0.03579556,\n",
       "        0.07712006],\n",
       "       [0.01811485, 0.03240313, 0.00738827, ..., 0.02692533, 0.01564765,\n",
       "        0.00873507]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# find the cosine similarity with TF-IDF for each text in the text with each text in the train\n",
    "cosine_similarity(tfidf_train, tfidf_test, dense_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f806d6a",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a092a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083321</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.118299</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>0.033229</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052374</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.109261</td>\n",
       "      <td>0.074325</td>\n",
       "      <td>0.077680</td>\n",
       "      <td>0.044835</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>0.054210</td>\n",
       "      <td>0.062434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.071159</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.042181</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>0.058933</td>\n",
       "      <td>0.022220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127364</td>\n",
       "      <td>0.064419</td>\n",
       "      <td>0.042193</td>\n",
       "      <td>0.182413</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.075831</td>\n",
       "      <td>0.092063</td>\n",
       "      <td>0.077248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066659</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.115229</td>\n",
       "      <td>0.157864</td>\n",
       "      <td>0.057421</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.052006</td>\n",
       "      <td>0.102023</td>\n",
       "      <td>0.060475</td>\n",
       "      <td>0.079891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.061443</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>0.049527</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>0.043404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.038819</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.047798</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.048921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064976</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.039684</td>\n",
       "      <td>0.111516</td>\n",
       "      <td>0.053901</td>\n",
       "      <td>0.081240</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>0.076142</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.076373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>0.051382</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.098721</td>\n",
       "      <td>0.032974</td>\n",
       "      <td>0.075335</td>\n",
       "      <td>0.021241</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.069777</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>0.036231</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.060590</td>\n",
       "      <td>0.062102</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.061808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.032490</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.026080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.016463</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.093904</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.054786</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.068297</td>\n",
       "      <td>0.078398</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.050899</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.040419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>0.037875</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.031965</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.030658</td>\n",
       "      <td>0.034410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036514</td>\n",
       "      <td>0.030329</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.024503</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.053235</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>0.077120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.018115</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.008735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 7532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.083321  0.035275  0.018537  0.118299  0.024184  0.080315  0.008866   \n",
       "1      0.032703  0.026554  0.013874  0.071159  0.013450  0.039661  0.011453   \n",
       "2      0.127364  0.064419  0.042193  0.182413  0.034789  0.112444  0.037736   \n",
       "3      0.034234  0.025749  0.027134  0.061443  0.028669  0.049527  0.007710   \n",
       "4      0.064976  0.028349  0.039684  0.111516  0.053901  0.081240  0.013304   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11309  0.051382  0.029407  0.022297  0.098721  0.032974  0.075335  0.021241   \n",
       "11310  0.045498  0.021226  0.035215  0.087389  0.018055  0.049514  0.006679   \n",
       "11311  0.043599  0.016463  0.020893  0.093904  0.018055  0.054786  0.012865   \n",
       "11312  0.049017  0.033791  0.037875  0.078300  0.031965  0.071797  0.007815   \n",
       "11313  0.018115  0.032403  0.007388  0.025770  0.011503  0.020655  0.004273   \n",
       "\n",
       "           7         8         9     ...      7522      7523      7524  \\\n",
       "0      0.058625  0.033229  0.038413  ...  0.052374  0.022142  0.073994   \n",
       "1      0.019183  0.028105  0.018120  ...  0.024914  0.018733  0.052463   \n",
       "2      0.075831  0.092063  0.077248  ...  0.066659  0.040664  0.115229   \n",
       "3      0.032078  0.028755  0.043404  ...  0.056760  0.020785  0.042762   \n",
       "4      0.038398  0.042316  0.038549  ...  0.043241  0.028911  0.077037   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11309  0.037797  0.034262  0.046881  ...  0.038940  0.016997  0.069777   \n",
       "11310  0.030908  0.032490  0.030894  ...  0.029142  0.018650  0.057320   \n",
       "11311  0.029916  0.034104  0.039360  ...  0.041040  0.017048  0.068297   \n",
       "11312  0.038323  0.030658  0.034410  ...  0.036514  0.030329  0.046550   \n",
       "11313  0.016415  0.016620  0.037245  ...  0.025160  0.015865  0.029204   \n",
       "\n",
       "           7525      7526      7527      7528      7529      7530      7531  \n",
       "0      0.109261  0.074325  0.077680  0.044835  0.087428  0.054210  0.062434  \n",
       "1      0.051162  0.021390  0.042181  0.032917  0.040388  0.058933  0.022220  \n",
       "2      0.157864  0.057421  0.116486  0.052006  0.102023  0.060475  0.079891  \n",
       "3      0.041888  0.014944  0.038819  0.017683  0.047798  0.032429  0.048921  \n",
       "4      0.084300  0.033363  0.079808  0.038025  0.076142  0.038687  0.076373  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11309  0.075766  0.036231  0.068229  0.060590  0.062102  0.030343  0.061808  \n",
       "11310  0.072220  0.025060  0.051189  0.036202  0.058369  0.027292  0.026080  \n",
       "11311  0.078398  0.024457  0.062752  0.014725  0.050899  0.020962  0.040419  \n",
       "11312  0.069400  0.024503  0.069067  0.024432  0.053235  0.035796  0.077120  \n",
       "11313  0.025829  0.020177  0.021120  0.012211  0.026925  0.015648  0.008735  \n",
       "\n",
       "[11314 rows x 7532 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cosine_similarity(tfidf_train, tfidf_test,  dense_output=True))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e595e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9048\n",
       "1        4114\n",
       "2        3172\n",
       "3       10575\n",
       "4       10278\n",
       "        ...  \n",
       "7527     9483\n",
       "7528     2850\n",
       "7529     6368\n",
       "7530     2965\n",
       "7531     9513\n",
       "Length: 7532, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the closet neighbor for each test using the cosine similarity\n",
    "tfidf_cos_predict = df.idxmax(axis = 0)\n",
    "tfidf_cos_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6fe2d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_text</th>\n",
       "      <th>per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4114</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3172</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10575</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10278</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>9483</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>2850</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>6368</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>2965</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>9513</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarity_text              per_group\n",
       "0               9048        sci.electronics\n",
       "1               4114              sci.crypt\n",
       "2               3172            alt.atheism\n",
       "3              10575              sci.crypt\n",
       "4              10278            alt.atheism\n",
       "...              ...                    ...\n",
       "7527            9483              sci.space\n",
       "7528            2850         comp.windows.x\n",
       "7529            6368       rec.sport.hockey\n",
       "7530            2965            alt.atheism\n",
       "7531            9513  comp.sys.mac.hardware\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the topic using the topic of the closet neighbor according to the cosine similarity\n",
    "\n",
    "new_df_tfidf = pd.DataFrame(columns=['similarity_text', 'per_group'])\n",
    "\n",
    "for i in range(len(tfidf_cos_predict.values)):\n",
    "    row_df = pd.DataFrame({'similarity_text': [tfidf_cos_predict.values[i]],'per_group': [news_group_target_names[news_group_target[tfidf_cos_predict.values[i]]]]})\n",
    "    new_df_tfidf = new_df_tfidf.append(row_df,ignore_index=True)\n",
    "new_df_tfidf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc3641",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf_dot_predict = pd.DataFrame()\n",
    "train_vectors = tfidf_train.toarray()\n",
    "test_vectors = tfidf_test.toarray()\n",
    "for test_count in range(len(test_vectors)):\n",
    "    vector_list= []\n",
    "    for train_count in range(len(train_vectors)):\n",
    "        vector_list.append(np.dot(test_vectors[test_count],train_vectors[train_count]))\n",
    "    df_tfidf_dot_predict[test_count] = vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319b906d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7522</th>\n",
       "      <th>7523</th>\n",
       "      <th>7524</th>\n",
       "      <th>7525</th>\n",
       "      <th>7526</th>\n",
       "      <th>7527</th>\n",
       "      <th>7528</th>\n",
       "      <th>7529</th>\n",
       "      <th>7530</th>\n",
       "      <th>7531</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083321</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.118299</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.058625</td>\n",
       "      <td>0.033229</td>\n",
       "      <td>0.038413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052374</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.109261</td>\n",
       "      <td>0.074325</td>\n",
       "      <td>0.077680</td>\n",
       "      <td>0.044835</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>0.054210</td>\n",
       "      <td>0.062434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.071159</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.042181</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>0.058933</td>\n",
       "      <td>0.022220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127364</td>\n",
       "      <td>0.064419</td>\n",
       "      <td>0.042193</td>\n",
       "      <td>0.182413</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.075831</td>\n",
       "      <td>0.092063</td>\n",
       "      <td>0.077248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066659</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.115229</td>\n",
       "      <td>0.157864</td>\n",
       "      <td>0.057421</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.052006</td>\n",
       "      <td>0.102023</td>\n",
       "      <td>0.060475</td>\n",
       "      <td>0.079891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.061443</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>0.049527</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>0.043404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.038819</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.047798</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.048921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064976</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.039684</td>\n",
       "      <td>0.111516</td>\n",
       "      <td>0.053901</td>\n",
       "      <td>0.081240</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>0.076142</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.076373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>0.051382</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.098721</td>\n",
       "      <td>0.032974</td>\n",
       "      <td>0.075335</td>\n",
       "      <td>0.021241</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.069777</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>0.036231</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.060590</td>\n",
       "      <td>0.062102</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.061808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.032490</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.026080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.016463</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.093904</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.054786</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.034104</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.068297</td>\n",
       "      <td>0.078398</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.050899</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.040419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>0.037875</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.031965</td>\n",
       "      <td>0.071797</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.030658</td>\n",
       "      <td>0.034410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036514</td>\n",
       "      <td>0.030329</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.024503</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.053235</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>0.077120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.018115</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.008735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 7532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.083321  0.035275  0.018537  0.118299  0.024184  0.080315  0.008866   \n",
       "1      0.032703  0.026554  0.013874  0.071159  0.013450  0.039661  0.011453   \n",
       "2      0.127364  0.064419  0.042193  0.182413  0.034789  0.112444  0.037736   \n",
       "3      0.034234  0.025749  0.027134  0.061443  0.028669  0.049527  0.007710   \n",
       "4      0.064976  0.028349  0.039684  0.111516  0.053901  0.081240  0.013304   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11309  0.051382  0.029407  0.022297  0.098721  0.032974  0.075335  0.021241   \n",
       "11310  0.045498  0.021226  0.035215  0.087389  0.018055  0.049514  0.006679   \n",
       "11311  0.043599  0.016463  0.020893  0.093904  0.018055  0.054786  0.012865   \n",
       "11312  0.049017  0.033791  0.037875  0.078300  0.031965  0.071797  0.007815   \n",
       "11313  0.018115  0.032403  0.007388  0.025770  0.011503  0.020655  0.004273   \n",
       "\n",
       "           7         8         9     ...      7522      7523      7524  \\\n",
       "0      0.058625  0.033229  0.038413  ...  0.052374  0.022142  0.073994   \n",
       "1      0.019183  0.028105  0.018120  ...  0.024914  0.018733  0.052463   \n",
       "2      0.075831  0.092063  0.077248  ...  0.066659  0.040664  0.115229   \n",
       "3      0.032078  0.028755  0.043404  ...  0.056760  0.020785  0.042762   \n",
       "4      0.038398  0.042316  0.038549  ...  0.043241  0.028911  0.077037   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11309  0.037797  0.034262  0.046881  ...  0.038940  0.016997  0.069777   \n",
       "11310  0.030908  0.032490  0.030894  ...  0.029142  0.018650  0.057320   \n",
       "11311  0.029916  0.034104  0.039360  ...  0.041040  0.017048  0.068297   \n",
       "11312  0.038323  0.030658  0.034410  ...  0.036514  0.030329  0.046550   \n",
       "11313  0.016415  0.016620  0.037245  ...  0.025160  0.015865  0.029204   \n",
       "\n",
       "           7525      7526      7527      7528      7529      7530      7531  \n",
       "0      0.109261  0.074325  0.077680  0.044835  0.087428  0.054210  0.062434  \n",
       "1      0.051162  0.021390  0.042181  0.032917  0.040388  0.058933  0.022220  \n",
       "2      0.157864  0.057421  0.116486  0.052006  0.102023  0.060475  0.079891  \n",
       "3      0.041888  0.014944  0.038819  0.017683  0.047798  0.032429  0.048921  \n",
       "4      0.084300  0.033363  0.079808  0.038025  0.076142  0.038687  0.076373  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11309  0.075766  0.036231  0.068229  0.060590  0.062102  0.030343  0.061808  \n",
       "11310  0.072220  0.025060  0.051189  0.036202  0.058369  0.027292  0.026080  \n",
       "11311  0.078398  0.024457  0.062752  0.014725  0.050899  0.020962  0.040419  \n",
       "11312  0.069400  0.024503  0.069067  0.024432  0.053235  0.035796  0.077120  \n",
       "11313  0.025829  0.020177  0.021120  0.012211  0.026925  0.015648  0.008735  \n",
       "\n",
       "[11314 rows x 7532 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628d0a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9048\n",
       "1        4114\n",
       "2        3172\n",
       "3       10575\n",
       "4       10278\n",
       "        ...  \n",
       "7527     9483\n",
       "7528     2850\n",
       "7529     6368\n",
       "7530     2965\n",
       "7531     9513\n",
       "Length: 7532, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the closet neighbor for each test using the dot product\n",
    "tfidf_dot_predict = df_tfidf_dot_predict.idxmax(axis = 0)\n",
    "tfidf_dot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "636a3ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_text</th>\n",
       "      <th>per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4114</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3172</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10575</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10278</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>9483</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>2850</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>6368</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>2965</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>9513</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarity_text              per_group\n",
       "0               9048        sci.electronics\n",
       "1               4114              sci.crypt\n",
       "2               3172            alt.atheism\n",
       "3              10575              sci.crypt\n",
       "4              10278            alt.atheism\n",
       "...              ...                    ...\n",
       "7527            9483              sci.space\n",
       "7528            2850         comp.windows.x\n",
       "7529            6368       rec.sport.hockey\n",
       "7530            2965            alt.atheism\n",
       "7531            9513  comp.sys.mac.hardware\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the topic using the topic of the closet neighbor according to the dot product\n",
    "new_df_tfidf = pd.DataFrame(columns=['similarity_text', 'per_group'])\n",
    "\n",
    "for i in range(len(tfidf_dot_predict.values)):\n",
    "    row_df = pd.DataFrame({'similarity_text': [tfidf_dot_predict.values[i]],'per_group': [news_group_target_names[news_group_target[tfidf_dot_predict.values[i]]]]})\n",
    "    new_df_tfidf = new_df_tfidf.append(row_df,ignore_index=True)\n",
    "new_df_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d616b0a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_text</th>\n",
       "      <th>per_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9048</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4114</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3172</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10575</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10278</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>9483</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>2850</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>6368</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>2965</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>9513</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarity_text              per_group\n",
       "0               9048        sci.electronics\n",
       "1               4114              sci.crypt\n",
       "2               3172            alt.atheism\n",
       "3              10575              sci.crypt\n",
       "4              10278            alt.atheism\n",
       "...              ...                    ...\n",
       "7527            9483              sci.space\n",
       "7528            2850         comp.windows.x\n",
       "7529            6368       rec.sport.hockey\n",
       "7530            2965            alt.atheism\n",
       "7531            9513  comp.sys.mac.hardware\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the topic using the topic of the closet neighbor according to the dot product\n",
    "new_df_tfidf = pd.DataFrame(columns=['similarity_text', 'per_group'])\n",
    "\n",
    "for i in range(len(tfidf_dot_predict.values)):\n",
    "    row_df = pd.DataFrame({'similarity_text': [tfidf_dot_predict.values[i]],'per_group': [news_group_target_names[news_group_target[tfidf_dot_predict.values[i]]]]})\n",
    "    new_df_tfidf = new_df_tfidf.append(row_df,ignore_index=True)\n",
    "new_df_tfidf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716baa1",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5899204",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-size: 20px\" dir='rtl'>\n",
    "    <b> דיון בתוצאות:    </b>\n",
    "</div>\n",
    "<br>\n",
    "<div dir='rtl'>\n",
    "    ניתן לשים לב שבשיטת ה-TFIDF קיבלנו תוצאות טובות יותר מאשר בשיטת ה- TF\n",
    "    כמו כן, תוצאת ה Cosine בכל אחת מהאפשרויות תמיד טובה יותר מה-Dot\n",
    "</div>\n",
    "<div dir='rtl'>\n",
    "    התוצאה הטובה ביותר התקבלה ב-TF-IDF כאשר היא זהה ל-TF Dot product (הסבר למטה למה זה קרה )\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37553532",
   "metadata": {},
   "source": [
    "## tf dot product accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bba266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35847052575677113"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dot_predict = tf_dot_predict.values\n",
    "tf_dot_predict = [news_group_target[i] for i in tf_dot_predict]\n",
    "accuracy_score(news_group_test.target, tf_dot_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e9cdb",
   "metadata": {},
   "source": [
    "## tf cos accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3ff023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383430695698353"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_cos_predict = df_tf_cos_predict.values\n",
    "df_tf_cos_predict = [news_group_target[i] for i in df_tf_cos_predict]\n",
    "\n",
    "accuracy_score(news_group_test.target, df_tf_cos_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4aa310",
   "metadata": {},
   "source": [
    "## tf-idf cos accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45041b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724641529474243"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_cos_predict = tfidf_cos_predict.values\n",
    "tfidf_cos_predict = [news_group_target[i] for i in tfidf_cos_predict]\n",
    "\n",
    "accuracy_score(news_group_test.target, tfidf_cos_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67fe09",
   "metadata": {},
   "source": [
    "## tf-idf dot product accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d89d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724641529474243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dot_predict = tfidf_dot_predict.values\n",
    "tfidf_dot_predict = [news_group_target[i] for i in tfidf_dot_predict]\n",
    "\n",
    "accuracy_score(news_group_test.target, tfidf_dot_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b89b89",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "    \n",
    "ניתן לראות שב-TFIDF הדיוק של ה-Cosine יצא זהה לדיוק של Dot product .\n",
    "הרצנו את החישוב על כמות טקסטים קטנה יותר וגילינו שהשוני הוא בספרה מאוד רחוקה אחרי הנקודה ולכן יצא זהה.\n",
    "    </div>\n",
    "    <br>\n",
    "    <div dir='rtl'>\n",
    "הוספנו פה קוד לדוגמה:\n",
    "</div>\n",
    "    <div dir='rtl'>\n",
    "לקחנו עשרה טקסטים מה-Test ו- Train ופעם אחת הרצנו Cos בפעם השנייה Dot וקיבלנו את אותם ווקטורים\n",
    "</div>\n",
    "  <div dir='rtl'>\n",
    "* הערה חשובה : אנחנו בנינו את הוקטור של Dot ולכן האיבר הראשון של כל מערך נמצא במערך הראשון ב-Cos וכך הלאה.\n",
    "    לדוגמה : \n",
    "    <br>dot[0][0] = cos[0][0] , dot[1][0] = cos[0][1] , dot[2][0] = cos [0][2]\n",
    "    כלומר בסופו של דבר קיבלנו את אותו DF ואת אותו ייצוג אך ה-Cos בונה את המערך בצורה שונה אך עדיין זהה לשלנו!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45b9c28f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04146014, 0.01678133, 0.00341898, 0.0210587 , 0.00877006,\n",
       "        0.01571061, 0.00172013, 0.01559119, 0.01281503, 0.01503676],\n",
       "       [0.00905899, 0.01879483, 0.00303131, 0.01918302, 0.0054784 ,\n",
       "        0.00780862, 0.00118769, 0.00392184, 0.01609298, 0.00286318],\n",
       "       [0.06248992, 0.03530185, 0.01074101, 0.02378894, 0.00628912,\n",
       "        0.02195819, 0.03409074, 0.02147107, 0.0544351 , 0.02172251],\n",
       "       [0.01530909, 0.01718815, 0.01334994, 0.01495707, 0.01674917,\n",
       "        0.01580445, 0.00594771, 0.00902019, 0.01642479, 0.02360123],\n",
       "       [0.02380781, 0.01285243, 0.0192736 , 0.01451655, 0.02849627,\n",
       "        0.02026429, 0.00598442, 0.00435259, 0.01367846, 0.00967355],\n",
       "       [0.00458201, 0.00713575, 0.00774956, 0.01918331, 0.01502714,\n",
       "        0.01729416, 0.01461944, 0.00439668, 0.01047133, 0.00176829],\n",
       "       [0.01866082, 0.00688357, 0.00357296, 0.00629498, 0.00441365,\n",
       "        0.01104234, 0.0017976 , 0.03882607, 0.00703882, 0.00365262],\n",
       "       [0.0173333 , 0.00857167, 0.01573207, 0.01046154, 0.00516953,\n",
       "        0.01266261, 0.00042796, 0.00236098, 0.0082338 , 0.00978598],\n",
       "       [0.00763645, 0.01332965, 0.00381016, 0.01060185, 0.00124941,\n",
       "        0.00819684, 0.00267759, 0.00625057, 0.0066859 , 0.00789791],\n",
       "       [0.01985888, 0.00768715, 0.00296694, 0.01143382, 0.00444025,\n",
       "        0.01554432, 0.00727682, 0.03927299, 0.01019135, 0.00471345]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors = tfidf_train[0:10].toarray()\n",
    "test_vectors = tfidf_test[0:10].toarray()\n",
    "vector_list= []\n",
    "for test_count in range(10):\n",
    "    vector_list.append(np.dot(train_vectors[0:10],test_vectors[test_count]))\n",
    "vector_listresult = cosine_similarity(tfidf_train[0:10], tfidf_test[0:10],  dense_output=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4f93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.04146014, 0.00905899, 0.06248992, 0.01530909, 0.02380781,\n",
       "        0.00458201, 0.01866082, 0.0173333 , 0.00763645, 0.01985888]),\n",
       " array([0.01678133, 0.01879483, 0.03530185, 0.01718815, 0.01285243,\n",
       "        0.00713575, 0.00688357, 0.00857167, 0.01332965, 0.00768715]),\n",
       " array([0.00341898, 0.00303131, 0.01074101, 0.01334994, 0.0192736 ,\n",
       "        0.00774956, 0.00357296, 0.01573207, 0.00381016, 0.00296694]),\n",
       " array([0.0210587 , 0.01918302, 0.02378894, 0.01495707, 0.01451655,\n",
       "        0.01918331, 0.00629498, 0.01046154, 0.01060185, 0.01143382]),\n",
       " array([0.00877006, 0.0054784 , 0.00628912, 0.01674917, 0.02849627,\n",
       "        0.01502714, 0.00441365, 0.00516953, 0.00124941, 0.00444025]),\n",
       " array([0.01571061, 0.00780862, 0.02195819, 0.01580445, 0.02026429,\n",
       "        0.01729416, 0.01104234, 0.01266261, 0.00819684, 0.01554432]),\n",
       " array([0.00172013, 0.00118769, 0.03409074, 0.00594771, 0.00598442,\n",
       "        0.01461944, 0.0017976 , 0.00042796, 0.00267759, 0.00727682]),\n",
       " array([0.01559119, 0.00392184, 0.02147107, 0.00902019, 0.00435259,\n",
       "        0.00439668, 0.03882607, 0.00236098, 0.00625057, 0.03927299]),\n",
       " array([0.01281503, 0.01609298, 0.0544351 , 0.01642479, 0.01367846,\n",
       "        0.01047133, 0.00703882, 0.0082338 , 0.0066859 , 0.01019135]),\n",
       " array([0.01503676, 0.00286318, 0.02172251, 0.02360123, 0.00967355,\n",
       "        0.00176829, 0.00365262, 0.00978598, 0.00789791, 0.00471345])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors = tfidf_train[0:10].toarray()\n",
    "test_vectors = tfidf_test[0:10].toarray()\n",
    "vector_list= []\n",
    "for test_count in range(10):\n",
    "    vector_list.append(np.dot(train_vectors[0:10],test_vectors[test_count]))\n",
    "vector_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168f310",
   "metadata": {},
   "source": [
    "# 'סעיף ג"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8f48a",
   "metadata": {},
   "source": [
    "### בחרנו להשתמש ב- TFIDF Cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85a0cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of group alt.atheismis 0.7429467084639498\n",
      "The most common mistake for this group is talk.religion.misc\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group sci.medis 0.5732323232323232\n",
      "The most common mistake for this group is talk.politics.misc\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group soc.religion.christianis 0.7688442211055276\n",
      "The most common mistake for this group is alt.atheism\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group comp.windows.xis 0.5822784810126582\n",
      "The most common mistake for this group is comp.os.ms-windows.misc\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group comp.graphicsis 0.5372750642673522\n",
      "The most common mistake for this group is comp.windows.x\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group talk.politics.mideastis 0.75\n",
      "The most common mistake for this group is alt.atheism\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group rec.motorcyclesis 0.8467336683417085\n",
      "The most common mistake for this group is rec.autos\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group talk.politics.gunsis 0.7307692307692307\n",
      "The most common mistake for this group is talk.politics.misc\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group misc.forsaleis 0.5128205128205128\n",
      "The most common mistake for this group is comp.sys.ibm.pc.hardware\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group sci.spaceis 0.8071065989847716\n",
      "The most common mistake for this group is comp.graphics\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group comp.sys.ibm.pc.hardwareis 0.6224489795918368\n",
      "The most common mistake for this group is comp.sys.mac.hardware\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group sci.cryptis 0.8257575757575758\n",
      "The most common mistake for this group is talk.politics.guns\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group rec.autosis 0.6893939393939394\n",
      "The most common mistake for this group is sci.electronics\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group comp.sys.mac.hardwareis 0.587012987012987\n",
      "The most common mistake for this group is comp.sys.ibm.pc.hardware\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group rec.sport.baseballis 0.7380352644836272\n",
      "The most common mistake for this group is rec.sport.hockey\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group comp.os.ms-windows.miscis 0.5050761421319797\n",
      "The most common mistake for this group is comp.sys.ibm.pc.hardware\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group talk.politics.miscis 0.6064516129032258\n",
      "The most common mistake for this group is talk.politics.guns\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group talk.religion.miscis 0.5896414342629482\n",
      "The most common mistake for this group is alt.atheism\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group sci.electronicsis 0.5623409669211196\n",
      "The most common mistake for this group is comp.sys.ibm.pc.hardware\n",
      "-------------------------------------------------------------------------\n",
      "The accuracy of group rec.sport.hockeyis 0.8370927318295739\n",
      "The most common mistake for this group is rec.sport.baseball\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "group_wrong_dic = {}\n",
    "group_accuracy_dic = {}\n",
    "\n",
    "for real,predict in zip(news_group_test.target,tfidf_cos_predict):\n",
    "    if(real not in group_wrong_dic.keys()):\n",
    "        group_wrong_dic[real] = list()\n",
    "    if(real == predict):\n",
    "        if(real not in group_accuracy_dic.keys()):\n",
    "            group_accuracy_dic[real] = 0\n",
    "        group_accuracy_dic[real] += 1\n",
    "    else:\n",
    "        group_wrong_dic[real].append(predict)\n",
    "\n",
    "for key in group_accuracy_dic.keys():\n",
    "    print(\"The accuracy of group \" + news_group_target_names[key] + \"is \" + str(group_accuracy_dic[key] / news_group_test.target.tolist().count(key)))\n",
    "    c = Counter(group_wrong_dic[key])\n",
    "    group_index = c.most_common(1)[0][0]\n",
    "    print(\"The most common mistake for this group is \" + news_group_target_names[group_index])\n",
    "    print(\"-------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
